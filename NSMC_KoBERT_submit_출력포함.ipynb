{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "NSMC_KoBERT_submit",
      "provenance": [],
      "collapsed_sections": [],
      "machine_shape": "hm",
      "authorship_tag": "ABX9TyP6ZVUA96ImcwbkH6FeFVDi",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "a3ce2f2d59af439a864f649272bff46c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_c1436f78a06446c18c2bbc9f54fc607b",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_6d946fe7dd784836bb5e29c75be0841c",
              "IPY_MODEL_17e50bc6a1784c0e8cd2fff4e309643b"
            ]
          }
        },
        "c1436f78a06446c18c2bbc9f54fc607b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "6d946fe7dd784836bb5e29c75be0841c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_3a0a5e00f23643b5b6d7922d57ddb958",
            "_dom_classes": [],
            "description": "Downloading: 100%",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 371391,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 371391,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_362a8a79fcee4b23940ac2a8e9f197ac"
          }
        },
        "17e50bc6a1784c0e8cd2fff4e309643b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_29e6dd62eb4c4ee183c022e364c2c4a6",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 371k/371k [00:01&lt;00:00, 204kB/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_f555ea3521084804ae88ca0b11a67349"
          }
        },
        "3a0a5e00f23643b5b6d7922d57ddb958": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "362a8a79fcee4b23940ac2a8e9f197ac": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "29e6dd62eb4c4ee183c022e364c2c4a6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "f555ea3521084804ae88ca0b11a67349": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "50469b60cd2b452b9f5b46729b53379e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_c5906b7c1db946039fbd5474557745fc",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_3ad834ff983944938956d810105bbd71",
              "IPY_MODEL_367e19fde4f741cd94d9b05cf0bf9440"
            ]
          }
        },
        "c5906b7c1db946039fbd5474557745fc": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "3ad834ff983944938956d810105bbd71": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_c045e14cad2c49f9976fa1044b3443e2",
            "_dom_classes": [],
            "description": "Downloading: 100%",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 77779,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 77779,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_efc392877f6349a3886e82b1cf3bf670"
          }
        },
        "367e19fde4f741cd94d9b05cf0bf9440": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_7efeba9d0bef42f9b2757b14ba085ebc",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 77.8k/77.8k [00:00&lt;00:00, 319kB/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_acfe6f55d80e4b30a6631b3051823264"
          }
        },
        "c045e14cad2c49f9976fa1044b3443e2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "efc392877f6349a3886e82b1cf3bf670": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "7efeba9d0bef42f9b2757b14ba085ebc": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "acfe6f55d80e4b30a6631b3051823264": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "3ea9fbd483534ddba88a4cac260b09f5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_af49b9c78d9048d685d0981e56652ee5",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_2429b04ba65449ef8606683302ffc7b6",
              "IPY_MODEL_9dcdafc684344e58af91af7702d3b0f0"
            ]
          }
        },
        "af49b9c78d9048d685d0981e56652ee5": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "2429b04ba65449ef8606683302ffc7b6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_4568f71f330d4cfa854ca1d800e8d31a",
            "_dom_classes": [],
            "description": "Downloading: 100%",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 426,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 426,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_a9ce680655ce4422b83b6b7408ca5da7"
          }
        },
        "9dcdafc684344e58af91af7702d3b0f0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_9e77ac4996744c4e9aaa9c64e7242433",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 426/426 [00:17&lt;00:00, 23.7B/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_eadcfa07fa3d40349845bd44497c6795"
          }
        },
        "4568f71f330d4cfa854ca1d800e8d31a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "a9ce680655ce4422b83b6b7408ca5da7": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "9e77ac4996744c4e9aaa9c64e7242433": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "eadcfa07fa3d40349845bd44497c6795": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "7ca03843cd7d4789ad324e522beb5f72": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_9944a24dd4be4ea8a00663801c2a0c1f",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_5ab9ff7245aa44f69ac5beb59a254c95",
              "IPY_MODEL_9463780b122942ce9f4c76f6e2e43e53"
            ]
          }
        },
        "9944a24dd4be4ea8a00663801c2a0c1f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "5ab9ff7245aa44f69ac5beb59a254c95": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_17f30439f67c4f4a88964d83927f88a5",
            "_dom_classes": [],
            "description": "Downloading: 100%",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 368792146,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 368792146,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_381086a51a3a4b7a83d8afd7edf2dcff"
          }
        },
        "9463780b122942ce9f4c76f6e2e43e53": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_922e8f80f7564f1b8f8f8885fcbe7d6b",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 369M/369M [00:07&lt;00:00, 47.8MB/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_9420ccb76c264550a7c230b27fc09772"
          }
        },
        "17f30439f67c4f4a88964d83927f88a5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "381086a51a3a4b7a83d8afd7edf2dcff": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "922e8f80f7564f1b8f8f8885fcbe7d6b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "9420ccb76c264550a7c230b27fc09772": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/heejin0223/NLPHW/blob/main/NSMC_KoBERT_submit_%EC%B6%9C%EB%A0%A5%ED%8F%AC%ED%95%A8.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EkYDNYi5tnAj"
      },
      "source": [
        "###### 데이터 출처 : https://github.com/e9t/nsmc.git   \r\n",
        "###### SKTBrain KoBERT 활용 : https://github.com/monologg/KoBERT-Transformers\r\n",
        "###### Rectified Adam Optimizer\r\n",
        "###### 소스참조 :\r\n",
        "- https://github.com/deepseasw/bert-naver-movie-review\r\n",
        "- https://github.com/kimwoonggon/publicservant_AI\r\n",
        "- https://github.com/monologg/KoBERT-Transformers\r\n",
        "- https://github.com/SKTBrain/KoBERT\r\n",
        "- SEQ_LEN = 128\r\n",
        "BATCH_SIZE = 32\r\n",
        "EPOCHS = 5"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "j0b6N3Eitjbb"
      },
      "source": [
        "#### setting"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "c5rg0MFuUQ69",
        "outputId": "f5eb7163-8156-4266-bce3-b52eeb32ddc5"
      },
      "source": [
        "import os\r\n",
        "from google.colab import drive\r\n",
        "drive.mount('/content/gdrive/')"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/gdrive/\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VxXNmsCnUbJ-"
      },
      "source": [
        "DATA_PATH = 'gdrive/My Drive/Colab Notebooks/NLP/'\r\n",
        "import sys\r\n",
        "sys.path.append(DATA_PATH)"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nIAoH9KoUkYB",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a3b791d5-467a-449e-bbc0-a70f2ae76c67"
      },
      "source": [
        "!pip install transformers --quiet"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\u001b[K     |████████████████████████████████| 1.5MB 13.3MB/s \n",
            "\u001b[K     |████████████████████████████████| 890kB 52.1MB/s \n",
            "\u001b[K     |████████████████████████████████| 2.9MB 62.8MB/s \n",
            "\u001b[?25h  Building wheel for sacremoses (setup.py) ... \u001b[?25l\u001b[?25hdone\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "E9dcLG1mUdst"
      },
      "source": [
        "import torch\r\n",
        "import tensorflow as tf\r\n",
        "import numpy as np\r\n",
        "import pandas as pd\r\n",
        "from transformers import *\r\n",
        "import json\r\n",
        "from tqdm import tqdm\r\n",
        "import math\r\n",
        "import urllib.request\r\n",
        "from sklearn.model_selection import train_test_split"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cVJXhzn1UjHI",
        "outputId": "4c8b14f4-23ef-4b61-8b1e-b3df72d0f899"
      },
      "source": [
        "if torch.cuda.is_available():    \r\n",
        "    device = torch.device(\"cuda\")\r\n",
        "    print('There are %d GPU(s) available.' % torch.cuda.device_count())\r\n",
        "    print('We will use the GPU:', torch.cuda.get_device_name(0))\r\n",
        "else:\r\n",
        "    device = torch.device(\"cpu\")\r\n",
        "    print('No GPU available, using the CPU instead.')"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "There are 1 GPU(s) available.\n",
            "We will use the GPU: Tesla V100-SXM2-16GB\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FxClcCvkVJer"
      },
      "source": [
        "#### data\r\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AsP6xVwjVHMA",
        "outputId": "66110ad7-2e56-46c7-d083-572d8f75fbcc"
      },
      "source": [
        "!git clone https://github.com/e9t/nsmc.git"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Cloning into 'nsmc'...\n",
            "remote: Enumerating objects: 14763, done.\u001b[K\n",
            "remote: Total 14763 (delta 0), reused 0 (delta 0), pack-reused 14763\u001b[K\n",
            "Receiving objects: 100% (14763/14763), 56.19 MiB | 13.96 MiB/s, done.\n",
            "Resolving deltas: 100% (1749/1749), done.\n",
            "Checking out files: 100% (14737/14737), done.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "b2KpdqRLZpiL",
        "outputId": "74f996e0-5e42-49de-cf80-5dfee7da35df"
      },
      "source": [
        "os.listdir('nsmc')"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['raw',\n",
              " 'ratings_test.txt',\n",
              " 'ratings.txt',\n",
              " 'README.md',\n",
              " 'code',\n",
              " '.git',\n",
              " 'synopses.json',\n",
              " 'ratings_train.txt']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0fSjrRPfVOwL",
        "outputId": "3855fc39-cad2-4677-e338-068fb2311245"
      },
      "source": [
        "total = pd.read_csv(\"nsmc/\"+\"ratings_train.txt\", sep='\\t')\r\n",
        "test = pd.read_csv(\"nsmc/\"+\"ratings_test.txt\", sep='\\t')\r\n",
        "print(total.shape)\r\n",
        "print(test.shape)"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(150000, 3)\n",
            "(50000, 3)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        },
        "id": "FAsYLj1xVRRL",
        "outputId": "a77f6750-1cf0-4de0-919e-0a992317f031"
      },
      "source": [
        "total[:5]"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>document</th>\n",
              "      <th>label</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>9976970</td>\n",
              "      <td>아 더빙.. 진짜 짜증나네요 목소리</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>3819312</td>\n",
              "      <td>흠...포스터보고 초딩영화줄....오버연기조차 가볍지 않구나</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>10265843</td>\n",
              "      <td>너무재밓었다그래서보는것을추천한다</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>9045019</td>\n",
              "      <td>교도소 이야기구먼 ..솔직히 재미는 없다..평점 조정</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>6483659</td>\n",
              "      <td>사이몬페그의 익살스런 연기가 돋보였던 영화!스파이더맨에서 늙어보이기만 했던 커스틴 ...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "         id                                           document  label\n",
              "0   9976970                                아 더빙.. 진짜 짜증나네요 목소리      0\n",
              "1   3819312                  흠...포스터보고 초딩영화줄....오버연기조차 가볍지 않구나      1\n",
              "2  10265843                                  너무재밓었다그래서보는것을추천한다      0\n",
              "3   9045019                      교도소 이야기구먼 ..솔직히 재미는 없다..평점 조정      0\n",
              "4   6483659  사이몬페그의 익살스런 연기가 돋보였던 영화!스파이더맨에서 늙어보이기만 했던 커스틴 ...      1"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 141
        },
        "id": "jy7w4TVoc4ch",
        "outputId": "917bec7b-5b56-4339-86e1-ff8c12331c36"
      },
      "source": [
        "total.columns = ['id','Sentence','label']\r\n",
        "total[:3]"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>Sentence</th>\n",
              "      <th>label</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>9976970</td>\n",
              "      <td>아 더빙.. 진짜 짜증나네요 목소리</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>3819312</td>\n",
              "      <td>흠...포스터보고 초딩영화줄....오버연기조차 가볍지 않구나</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>10265843</td>\n",
              "      <td>너무재밓었다그래서보는것을추천한다</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "         id                           Sentence  label\n",
              "0   9976970                아 더빙.. 진짜 짜증나네요 목소리      0\n",
              "1   3819312  흠...포스터보고 초딩영화줄....오버연기조차 가볍지 않구나      1\n",
              "2  10265843                  너무재밓었다그래서보는것을추천한다      0"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 141
        },
        "id": "ihWGPJFTJwQr",
        "outputId": "772a9496-f351-4f26-b0d3-3fd5ddb0d85c"
      },
      "source": [
        "test.columns = ['id','Sentence','label']\r\n",
        "test[:3]"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>Sentence</th>\n",
              "      <th>label</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>6270596</td>\n",
              "      <td>굳 ㅋ</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>9274899</td>\n",
              "      <td>GDNTOPCLASSINTHECLUB</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>8544678</td>\n",
              "      <td>뭐야 이 평점들은.... 나쁘진 않지만 10점 짜리는 더더욱 아니잖아</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "        id                                Sentence  label\n",
              "0  6270596                                     굳 ㅋ      1\n",
              "1  9274899                    GDNTOPCLASSINTHECLUB      0\n",
              "2  8544678  뭐야 이 평점들은.... 나쁘진 않지만 10점 짜리는 더더욱 아니잖아      0"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Rtbj12ZEG0eM"
      },
      "source": [
        "train, val = train_test_split(total, \r\n",
        "                                    test_size=0.15, \r\n",
        "                                    random_state=42, \r\n",
        "                                    stratify=total.label.values)"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Sl4s3a9PHYre"
      },
      "source": [
        "train = train.reset_index(drop=True)\r\n",
        "val = val.reset_index(drop=True)"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eKnmAdPCHyKF",
        "outputId": "e3fb72af-e248-4b5c-d0d1-144a2cb1fe2d"
      },
      "source": [
        "print(len(train))\r\n",
        "print(len(val))"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "127500\n",
            "22500\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "poGtO7k0Vd0S"
      },
      "source": [
        "#### tokenizer"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bbqvGS_qZx2j",
        "outputId": "dc315d80-40e8-4cc1-9026-47074c1716ae"
      },
      "source": [
        "!pip install sentencepiece "
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting sentencepiece\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/e5/2d/6d4ca4bef9a67070fa1cac508606328329152b1df10bdf31fb6e4e727894/sentencepiece-0.1.94-cp36-cp36m-manylinux2014_x86_64.whl (1.1MB)\n",
            "\r\u001b[K     |▎                               | 10kB 24.1MB/s eta 0:00:01\r\u001b[K     |▋                               | 20kB 29.4MB/s eta 0:00:01\r\u001b[K     |▉                               | 30kB 18.7MB/s eta 0:00:01\r\u001b[K     |█▏                              | 40kB 10.0MB/s eta 0:00:01\r\u001b[K     |█▌                              | 51kB 11.9MB/s eta 0:00:01\r\u001b[K     |█▊                              | 61kB 11.9MB/s eta 0:00:01\r\u001b[K     |██                              | 71kB 12.3MB/s eta 0:00:01\r\u001b[K     |██▍                             | 81kB 13.5MB/s eta 0:00:01\r\u001b[K     |██▋                             | 92kB 13.5MB/s eta 0:00:01\r\u001b[K     |███                             | 102kB 12.6MB/s eta 0:00:01\r\u001b[K     |███▎                            | 112kB 12.6MB/s eta 0:00:01\r\u001b[K     |███▌                            | 122kB 12.6MB/s eta 0:00:01\r\u001b[K     |███▉                            | 133kB 12.6MB/s eta 0:00:01\r\u001b[K     |████▏                           | 143kB 12.6MB/s eta 0:00:01\r\u001b[K     |████▍                           | 153kB 12.6MB/s eta 0:00:01\r\u001b[K     |████▊                           | 163kB 12.6MB/s eta 0:00:01\r\u001b[K     |█████                           | 174kB 12.6MB/s eta 0:00:01\r\u001b[K     |█████▎                          | 184kB 12.6MB/s eta 0:00:01\r\u001b[K     |█████▋                          | 194kB 12.6MB/s eta 0:00:01\r\u001b[K     |█████▉                          | 204kB 12.6MB/s eta 0:00:01\r\u001b[K     |██████▏                         | 215kB 12.6MB/s eta 0:00:01\r\u001b[K     |██████▌                         | 225kB 12.6MB/s eta 0:00:01\r\u001b[K     |██████▊                         | 235kB 12.6MB/s eta 0:00:01\r\u001b[K     |███████                         | 245kB 12.6MB/s eta 0:00:01\r\u001b[K     |███████▍                        | 256kB 12.6MB/s eta 0:00:01\r\u001b[K     |███████▋                        | 266kB 12.6MB/s eta 0:00:01\r\u001b[K     |████████                        | 276kB 12.6MB/s eta 0:00:01\r\u001b[K     |████████▎                       | 286kB 12.6MB/s eta 0:00:01\r\u001b[K     |████████▌                       | 296kB 12.6MB/s eta 0:00:01\r\u001b[K     |████████▉                       | 307kB 12.6MB/s eta 0:00:01\r\u001b[K     |█████████                       | 317kB 12.6MB/s eta 0:00:01\r\u001b[K     |█████████▍                      | 327kB 12.6MB/s eta 0:00:01\r\u001b[K     |█████████▊                      | 337kB 12.6MB/s eta 0:00:01\r\u001b[K     |██████████                      | 348kB 12.6MB/s eta 0:00:01\r\u001b[K     |██████████▎                     | 358kB 12.6MB/s eta 0:00:01\r\u001b[K     |██████████▋                     | 368kB 12.6MB/s eta 0:00:01\r\u001b[K     |██████████▉                     | 378kB 12.6MB/s eta 0:00:01\r\u001b[K     |███████████▏                    | 389kB 12.6MB/s eta 0:00:01\r\u001b[K     |███████████▌                    | 399kB 12.6MB/s eta 0:00:01\r\u001b[K     |███████████▊                    | 409kB 12.6MB/s eta 0:00:01\r\u001b[K     |████████████                    | 419kB 12.6MB/s eta 0:00:01\r\u001b[K     |████████████▍                   | 430kB 12.6MB/s eta 0:00:01\r\u001b[K     |████████████▋                   | 440kB 12.6MB/s eta 0:00:01\r\u001b[K     |█████████████                   | 450kB 12.6MB/s eta 0:00:01\r\u001b[K     |█████████████▎                  | 460kB 12.6MB/s eta 0:00:01\r\u001b[K     |█████████████▌                  | 471kB 12.6MB/s eta 0:00:01\r\u001b[K     |█████████████▉                  | 481kB 12.6MB/s eta 0:00:01\r\u001b[K     |██████████████                  | 491kB 12.6MB/s eta 0:00:01\r\u001b[K     |██████████████▍                 | 501kB 12.6MB/s eta 0:00:01\r\u001b[K     |██████████████▊                 | 512kB 12.6MB/s eta 0:00:01\r\u001b[K     |███████████████                 | 522kB 12.6MB/s eta 0:00:01\r\u001b[K     |███████████████▎                | 532kB 12.6MB/s eta 0:00:01\r\u001b[K     |███████████████▋                | 542kB 12.6MB/s eta 0:00:01\r\u001b[K     |███████████████▉                | 552kB 12.6MB/s eta 0:00:01\r\u001b[K     |████████████████▏               | 563kB 12.6MB/s eta 0:00:01\r\u001b[K     |████████████████▌               | 573kB 12.6MB/s eta 0:00:01\r\u001b[K     |████████████████▊               | 583kB 12.6MB/s eta 0:00:01\r\u001b[K     |█████████████████               | 593kB 12.6MB/s eta 0:00:01\r\u001b[K     |█████████████████▍              | 604kB 12.6MB/s eta 0:00:01\r\u001b[K     |█████████████████▋              | 614kB 12.6MB/s eta 0:00:01\r\u001b[K     |██████████████████              | 624kB 12.6MB/s eta 0:00:01\r\u001b[K     |██████████████████▏             | 634kB 12.6MB/s eta 0:00:01\r\u001b[K     |██████████████████▌             | 645kB 12.6MB/s eta 0:00:01\r\u001b[K     |██████████████████▉             | 655kB 12.6MB/s eta 0:00:01\r\u001b[K     |███████████████████             | 665kB 12.6MB/s eta 0:00:01\r\u001b[K     |███████████████████▍            | 675kB 12.6MB/s eta 0:00:01\r\u001b[K     |███████████████████▊            | 686kB 12.6MB/s eta 0:00:01\r\u001b[K     |████████████████████            | 696kB 12.6MB/s eta 0:00:01\r\u001b[K     |████████████████████▎           | 706kB 12.6MB/s eta 0:00:01\r\u001b[K     |████████████████████▋           | 716kB 12.6MB/s eta 0:00:01\r\u001b[K     |████████████████████▉           | 727kB 12.6MB/s eta 0:00:01\r\u001b[K     |█████████████████████▏          | 737kB 12.6MB/s eta 0:00:01\r\u001b[K     |█████████████████████▌          | 747kB 12.6MB/s eta 0:00:01\r\u001b[K     |█████████████████████▊          | 757kB 12.6MB/s eta 0:00:01\r\u001b[K     |██████████████████████          | 768kB 12.6MB/s eta 0:00:01\r\u001b[K     |██████████████████████▎         | 778kB 12.6MB/s eta 0:00:01\r\u001b[K     |██████████████████████▋         | 788kB 12.6MB/s eta 0:00:01\r\u001b[K     |███████████████████████         | 798kB 12.6MB/s eta 0:00:01\r\u001b[K     |███████████████████████▏        | 808kB 12.6MB/s eta 0:00:01\r\u001b[K     |███████████████████████▌        | 819kB 12.6MB/s eta 0:00:01\r\u001b[K     |███████████████████████▉        | 829kB 12.6MB/s eta 0:00:01\r\u001b[K     |████████████████████████        | 839kB 12.6MB/s eta 0:00:01\r\u001b[K     |████████████████████████▍       | 849kB 12.6MB/s eta 0:00:01\r\u001b[K     |████████████████████████▊       | 860kB 12.6MB/s eta 0:00:01\r\u001b[K     |█████████████████████████       | 870kB 12.6MB/s eta 0:00:01\r\u001b[K     |█████████████████████████▎      | 880kB 12.6MB/s eta 0:00:01\r\u001b[K     |█████████████████████████▋      | 890kB 12.6MB/s eta 0:00:01\r\u001b[K     |█████████████████████████▉      | 901kB 12.6MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▏     | 911kB 12.6MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▌     | 921kB 12.6MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▊     | 931kB 12.6MB/s eta 0:00:01\r\u001b[K     |███████████████████████████     | 942kB 12.6MB/s eta 0:00:01\r\u001b[K     |███████████████████████████▎    | 952kB 12.6MB/s eta 0:00:01\r\u001b[K     |███████████████████████████▋    | 962kB 12.6MB/s eta 0:00:01\r\u001b[K     |████████████████████████████    | 972kB 12.6MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▏   | 983kB 12.6MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▌   | 993kB 12.6MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▉   | 1.0MB 12.6MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████   | 1.0MB 12.6MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▍  | 1.0MB 12.6MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▊  | 1.0MB 12.6MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████  | 1.0MB 12.6MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▎ | 1.1MB 12.6MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▋ | 1.1MB 12.6MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▉ | 1.1MB 12.6MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▏| 1.1MB 12.6MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▍| 1.1MB 12.6MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▊| 1.1MB 12.6MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 1.1MB 12.6MB/s \n",
            "\u001b[?25hInstalling collected packages: sentencepiece\n",
            "Successfully installed sentencepiece-0.1.94\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GBz2CGqGZ4dC"
      },
      "source": [
        "## https://github.com/monologg/KoBERT-Transformers : Tokenizer설정\r\n",
        "\r\n",
        "import logging\r\n",
        "import os\r\n",
        "import unicodedata\r\n",
        "from shutil import copyfile\r\n",
        "\r\n",
        "from transformers import PreTrainedTokenizer\r\n",
        "\r\n",
        "\r\n",
        "logger = logging.getLogger(__name__)\r\n",
        "\r\n",
        "VOCAB_FILES_NAMES = {\"vocab_file\": \"tokenizer_78b3253a26.model\",\r\n",
        "                     \"vocab_txt\": \"vocab.txt\"}\r\n",
        "\r\n",
        "PRETRAINED_VOCAB_FILES_MAP = {\r\n",
        "    \"vocab_file\": {\r\n",
        "        \"monologg/kobert\": \"https://s3.amazonaws.com/models.huggingface.co/bert/monologg/kobert/tokenizer_78b3253a26.model\",\r\n",
        "        \"monologg/kobert-lm\": \"https://s3.amazonaws.com/models.huggingface.co/bert/monologg/kobert-lm/tokenizer_78b3253a26.model\",\r\n",
        "        \"monologg/distilkobert\": \"https://s3.amazonaws.com/models.huggingface.co/bert/monologg/distilkobert/tokenizer_78b3253a26.model\"\r\n",
        "    },\r\n",
        "    \"vocab_txt\": {\r\n",
        "        \"monologg/kobert\": \"https://s3.amazonaws.com/models.huggingface.co/bert/monologg/kobert/vocab.txt\",\r\n",
        "        \"monologg/kobert-lm\": \"https://s3.amazonaws.com/models.huggingface.co/bert/monologg/kobert-lm/vocab.txt\",\r\n",
        "        \"monologg/distilkobert\": \"https://s3.amazonaws.com/models.huggingface.co/bert/monologg/distilkobert/vocab.txt\"\r\n",
        "    }\r\n",
        "}\r\n",
        "\r\n",
        "PRETRAINED_POSITIONAL_EMBEDDINGS_SIZES = {\r\n",
        "    \"monologg/kobert\": 512,\r\n",
        "    \"monologg/kobert-lm\": 512,\r\n",
        "    \"monologg/distilkobert\": 512\r\n",
        "}\r\n",
        "\r\n",
        "PRETRAINED_INIT_CONFIGURATION = {\r\n",
        "    \"monologg/kobert\": {\"do_lower_case\": False},\r\n",
        "    \"monologg/kobert-lm\": {\"do_lower_case\": False},\r\n",
        "    \"monologg/distilkobert\": {\"do_lower_case\": False}\r\n",
        "}\r\n",
        "\r\n",
        "SPIECE_UNDERLINE = u'▁'\r\n",
        "\r\n",
        "\r\n",
        "class KoBertTokenizer(PreTrainedTokenizer):\r\n",
        "    \"\"\"\r\n",
        "        SentencePiece based tokenizer. Peculiarities:\r\n",
        "            - requires `SentencePiece <https://github.com/google/sentencepiece>`_\r\n",
        "    \"\"\"\r\n",
        "    vocab_files_names = VOCAB_FILES_NAMES\r\n",
        "    pretrained_vocab_files_map = PRETRAINED_VOCAB_FILES_MAP\r\n",
        "    pretrained_init_configuration = PRETRAINED_INIT_CONFIGURATION\r\n",
        "    max_model_input_sizes = PRETRAINED_POSITIONAL_EMBEDDINGS_SIZES\r\n",
        "\r\n",
        "    def __init__(\r\n",
        "            self,\r\n",
        "            vocab_file,\r\n",
        "            vocab_txt,\r\n",
        "            do_lower_case=False,\r\n",
        "            remove_space=True,\r\n",
        "            keep_accents=False,\r\n",
        "            unk_token=\"[UNK]\",\r\n",
        "            sep_token=\"[SEP]\",\r\n",
        "            pad_token=\"[PAD]\",\r\n",
        "            cls_token=\"[CLS]\",\r\n",
        "            mask_token=\"[MASK]\",\r\n",
        "            **kwargs):\r\n",
        "        super().__init__(\r\n",
        "            unk_token=unk_token,\r\n",
        "            sep_token=sep_token,\r\n",
        "            pad_token=pad_token,\r\n",
        "            cls_token=cls_token,\r\n",
        "            mask_token=mask_token,\r\n",
        "            **kwargs\r\n",
        "        )\r\n",
        "\r\n",
        "        # Build vocab\r\n",
        "        self.token2idx = dict()\r\n",
        "        self.idx2token = []\r\n",
        "        with open(vocab_txt, 'r', encoding='utf-8') as f:\r\n",
        "            for idx, token in enumerate(f):\r\n",
        "                token = token.strip()\r\n",
        "                self.token2idx[token] = idx\r\n",
        "                self.idx2token.append(token)\r\n",
        "\r\n",
        "        try:\r\n",
        "            import sentencepiece as spm\r\n",
        "        except ImportError:\r\n",
        "            logger.warning(\"You need to install SentencePiece to use KoBertTokenizer: https://github.com/google/sentencepiece\"\r\n",
        "                           \"pip install sentencepiece\")\r\n",
        "\r\n",
        "        self.do_lower_case = do_lower_case\r\n",
        "        self.remove_space = remove_space\r\n",
        "        self.keep_accents = keep_accents\r\n",
        "        self.vocab_file = vocab_file\r\n",
        "        self.vocab_txt = vocab_txt\r\n",
        "\r\n",
        "        self.sp_model = spm.SentencePieceProcessor()\r\n",
        "        self.sp_model.Load(vocab_file)\r\n",
        "\r\n",
        "    @property\r\n",
        "    def vocab_size(self):\r\n",
        "        return len(self.idx2token)\r\n",
        "\r\n",
        "    def get_vocab(self):\r\n",
        "        return dict(self.token2idx, **self.added_tokens_encoder)\r\n",
        "\r\n",
        "    def __getstate__(self):\r\n",
        "        state = self.__dict__.copy()\r\n",
        "        state[\"sp_model\"] = None\r\n",
        "        return state\r\n",
        "\r\n",
        "    def __setstate__(self, d):\r\n",
        "        self.__dict__ = d\r\n",
        "        try:\r\n",
        "            import sentencepiece as spm\r\n",
        "        except ImportError:\r\n",
        "            logger.warning(\"You need to install SentencePiece to use KoBertTokenizer: https://github.com/google/sentencepiece\"\r\n",
        "                           \"pip install sentencepiece\")\r\n",
        "        self.sp_model = spm.SentencePieceProcessor()\r\n",
        "        self.sp_model.Load(self.vocab_file)\r\n",
        "\r\n",
        "    def preprocess_text(self, inputs):\r\n",
        "        if self.remove_space:\r\n",
        "            outputs = \" \".join(inputs.strip().split())\r\n",
        "        else:\r\n",
        "            outputs = inputs\r\n",
        "        outputs = outputs.replace(\"``\", '\"').replace(\"''\", '\"')\r\n",
        "\r\n",
        "        if not self.keep_accents:\r\n",
        "            outputs = unicodedata.normalize('NFKD', outputs)\r\n",
        "            outputs = \"\".join([c for c in outputs if not unicodedata.combining(c)])\r\n",
        "        if self.do_lower_case:\r\n",
        "            outputs = outputs.lower()\r\n",
        "\r\n",
        "        return outputs\r\n",
        "\r\n",
        "    def _tokenize(self, text, return_unicode=True, sample=False):\r\n",
        "        \"\"\" Tokenize a string. \"\"\"\r\n",
        "        text = self.preprocess_text(text)\r\n",
        "\r\n",
        "        if not sample:\r\n",
        "            pieces = self.sp_model.EncodeAsPieces(text)\r\n",
        "        else:\r\n",
        "            pieces = self.sp_model.SampleEncodeAsPieces(text, 64, 0.1)\r\n",
        "        new_pieces = []\r\n",
        "        for piece in pieces:\r\n",
        "            if len(piece) > 1 and piece[-1] == str(\",\") and piece[-2].isdigit():\r\n",
        "                cur_pieces = self.sp_model.EncodeAsPieces(piece[:-1].replace(SPIECE_UNDERLINE, \"\"))\r\n",
        "                if piece[0] != SPIECE_UNDERLINE and cur_pieces[0][0] == SPIECE_UNDERLINE:\r\n",
        "                    if len(cur_pieces[0]) == 1:\r\n",
        "                        cur_pieces = cur_pieces[1:]\r\n",
        "                    else:\r\n",
        "                        cur_pieces[0] = cur_pieces[0][1:]\r\n",
        "                cur_pieces.append(piece[-1])\r\n",
        "                new_pieces.extend(cur_pieces)\r\n",
        "            else:\r\n",
        "                new_pieces.append(piece)\r\n",
        "\r\n",
        "        return new_pieces\r\n",
        "\r\n",
        "    def _convert_token_to_id(self, token):\r\n",
        "        \"\"\" Converts a token (str/unicode) in an id using the vocab. \"\"\"\r\n",
        "        return self.token2idx.get(token, self.token2idx[self.unk_token])\r\n",
        "\r\n",
        "    def _convert_id_to_token(self, index, return_unicode=True):\r\n",
        "        \"\"\"Converts an index (integer) in a token (string/unicode) using the vocab.\"\"\"\r\n",
        "        return self.idx2token[index]\r\n",
        "\r\n",
        "    def convert_tokens_to_string(self, tokens):\r\n",
        "        \"\"\"Converts a sequence of tokens (strings for sub-words) in a single string.\"\"\"\r\n",
        "        out_string = \"\".join(tokens).replace(SPIECE_UNDERLINE, \" \").strip()\r\n",
        "        return out_string\r\n",
        "\r\n",
        "    def build_inputs_with_special_tokens(self, token_ids_0, token_ids_1=None):\r\n",
        "        \"\"\"\r\n",
        "        Build model inputs from a sequence or a pair of sequence for sequence classification tasks\r\n",
        "        by concatenating and adding special tokens.\r\n",
        "        A KoBERT sequence has the following format:\r\n",
        "            single sequence: [CLS] X [SEP]\r\n",
        "            pair of sequences: [CLS] A [SEP] B [SEP]\r\n",
        "        \"\"\"\r\n",
        "        if token_ids_1 is None:\r\n",
        "            return [self.cls_token_id] + token_ids_0 + [self.sep_token_id]\r\n",
        "        cls = [self.cls_token_id]\r\n",
        "        sep = [self.sep_token_id]\r\n",
        "        return cls + token_ids_0 + sep + token_ids_1 + sep\r\n",
        "\r\n",
        "    def get_special_tokens_mask(self, token_ids_0, token_ids_1=None, already_has_special_tokens=False):\r\n",
        "        \"\"\"\r\n",
        "        Retrieves sequence ids from a token list that has no special tokens added. This method is called when adding\r\n",
        "        special tokens using the tokenizer ``prepare_for_model`` or ``encode_plus`` methods.\r\n",
        "        Args:\r\n",
        "            token_ids_0: list of ids (must not contain special tokens)\r\n",
        "            token_ids_1: Optional list of ids (must not contain special tokens), necessary when fetching sequence ids\r\n",
        "                for sequence pairs\r\n",
        "            already_has_special_tokens: (default False) Set to True if the token list is already formated with\r\n",
        "                special tokens for the model\r\n",
        "        Returns:\r\n",
        "            A list of integers in the range [0, 1]: 0 for a special token, 1 for a sequence token.\r\n",
        "        \"\"\"\r\n",
        "\r\n",
        "        if already_has_special_tokens:\r\n",
        "            if token_ids_1 is not None:\r\n",
        "                raise ValueError(\r\n",
        "                    \"You should not supply a second sequence if the provided sequence of \"\r\n",
        "                    \"ids is already formated with special tokens for the model.\"\r\n",
        "                )\r\n",
        "            return list(map(lambda x: 1 if x in [self.sep_token_id, self.cls_token_id] else 0, token_ids_0))\r\n",
        "\r\n",
        "        if token_ids_1 is not None:\r\n",
        "            return [1] + ([0] * len(token_ids_0)) + [1] + ([0] * len(token_ids_1)) + [1]\r\n",
        "        return [1] + ([0] * len(token_ids_0)) + [1]\r\n",
        "\r\n",
        "    def create_token_type_ids_from_sequences(self, token_ids_0, token_ids_1=None):\r\n",
        "        \"\"\"\r\n",
        "        Creates a mask from the two sequences passed to be used in a sequence-pair classification task.\r\n",
        "        A KoBERT sequence pair mask has the following format:\r\n",
        "        0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1\r\n",
        "        | first sequence    | second sequence\r\n",
        "        if token_ids_1 is None, only returns the first portion of the mask (0's).\r\n",
        "        \"\"\"\r\n",
        "        sep = [self.sep_token_id]\r\n",
        "        cls = [self.cls_token_id]\r\n",
        "        if token_ids_1 is None:\r\n",
        "            return len(cls + token_ids_0 + sep) * [0]\r\n",
        "        return len(cls + token_ids_0 + sep) * [0] + len(token_ids_1 + sep) * [1]\r\n",
        "\r\n",
        "    def save_vocabulary(self, save_directory):\r\n",
        "        \"\"\" Save the sentencepiece vocabulary (copy original file) and special tokens file\r\n",
        "            to a directory.\r\n",
        "        \"\"\"\r\n",
        "        if not os.path.isdir(save_directory):\r\n",
        "            logger.error(\"Vocabulary path ({}) should be a directory\".format(save_directory))\r\n",
        "            return\r\n",
        "\r\n",
        "        # 1. Save sentencepiece model\r\n",
        "        out_vocab_model = os.path.join(save_directory, VOCAB_FILES_NAMES[\"vocab_file\"])\r\n",
        "\r\n",
        "        if os.path.abspath(self.vocab_file) != os.path.abspath(out_vocab_model):\r\n",
        "            copyfile(self.vocab_file, out_vocab_model)\r\n",
        "\r\n",
        "        # 2. Save vocab.txt\r\n",
        "        index = 0\r\n",
        "        out_vocab_txt = os.path.join(save_directory, VOCAB_FILES_NAMES[\"vocab_txt\"])\r\n",
        "        with open(out_vocab_txt, \"w\", encoding=\"utf-8\") as writer:\r\n",
        "            for token, token_index in sorted(self.token2idx.items(), key=lambda kv: kv[1]):\r\n",
        "                if index != token_index:\r\n",
        "                    logger.warning(\r\n",
        "                        \"Saving vocabulary to {}: vocabulary indices are not consecutive.\"\r\n",
        "                        \" Please check that the vocabulary is not corrupted!\".format(out_vocab_txt)\r\n",
        "                    )\r\n",
        "                    index = token_index\r\n",
        "                writer.write(token + \"\\n\")\r\n",
        "                index += 1\r\n",
        "\r\n",
        "        return out_vocab_model, out_vocab_txt"
      ],
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rn0_7wyhZ9Ht",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 117,
          "referenced_widgets": [
            "a3ce2f2d59af439a864f649272bff46c",
            "c1436f78a06446c18c2bbc9f54fc607b",
            "6d946fe7dd784836bb5e29c75be0841c",
            "17e50bc6a1784c0e8cd2fff4e309643b",
            "3a0a5e00f23643b5b6d7922d57ddb958",
            "362a8a79fcee4b23940ac2a8e9f197ac",
            "29e6dd62eb4c4ee183c022e364c2c4a6",
            "f555ea3521084804ae88ca0b11a67349",
            "50469b60cd2b452b9f5b46729b53379e",
            "c5906b7c1db946039fbd5474557745fc",
            "3ad834ff983944938956d810105bbd71",
            "367e19fde4f741cd94d9b05cf0bf9440",
            "c045e14cad2c49f9976fa1044b3443e2",
            "efc392877f6349a3886e82b1cf3bf670",
            "7efeba9d0bef42f9b2757b14ba085ebc",
            "acfe6f55d80e4b30a6631b3051823264"
          ]
        },
        "outputId": "2f57cd86-1607-440a-ca22-e49d6af57b31"
      },
      "source": [
        "tokenizer = KoBertTokenizer.from_pretrained('monologg/kobert')"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "a3ce2f2d59af439a864f649272bff46c",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=371391.0, style=ProgressStyle(descripti…"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "50469b60cd2b452b9f5b46729b53379e",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=77779.0, style=ProgressStyle(descriptio…"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WgIB8sRdNayd"
      },
      "source": [
        "#### inputs"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NRnbIBZTQTaM"
      },
      "source": [
        "SEQ_LEN = 128\r\n",
        "BATCH_SIZE = 32\r\n",
        "EPOCHS = 5\r\n",
        "ITERATIONS = math.ceil(len(train)//BATCH_SIZE)"
      ],
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Y34s0WKvVvAS"
      },
      "source": [
        "def convert_data(data_df):\r\n",
        "    global tokenizer\r\n",
        "    \r\n",
        "#    SEQ_LEN = MAX_LEN    \r\n",
        "    \r\n",
        "    tokens, masks, segments, targets = [], [], [], []\r\n",
        "    \r\n",
        "    for i in tqdm(range(len(data_df))):\r\n",
        "        # 토큰 : 문장을 토큰화한 값\r\n",
        "        token = tokenizer.encode(data_df[DATA_COLUMN][i], max_length=SEQ_LEN, pad_to_max_length=True)\r\n",
        "       \r\n",
        "        # 마스크 : 토큰화한 문장 중 패딩은 0, 문자는 1\r\n",
        "        num_zeros = token.count(0)\r\n",
        "        mask = [1]*(SEQ_LEN-num_zeros) + [0]*num_zeros\r\n",
        "        \r\n",
        "        # 세그먼트 : 문장의 전후관계 구분 (단일문장은 전후관계 없으므로 모두 0)\r\n",
        "        segment = [0]*SEQ_LEN\r\n",
        "\r\n",
        "        # 버트 인풋값을 각각 tokens,masks, segments에 저장\r\n",
        "        tokens.append(token)\r\n",
        "        masks.append(mask)\r\n",
        "        segments.append(segment)\r\n",
        "        \r\n",
        "        # 정답label을 targets에 저장\r\n",
        "        targets.append(data_df[LABEL_COLUMN][i])\r\n",
        "\r\n",
        "    # tokens, masks, segments, targets를 numpy array로 지정    \r\n",
        "    tokens = np.array(tokens)\r\n",
        "    masks = np.array(masks)\r\n",
        "    segments = np.array(segments)\r\n",
        "    targets = np.array(targets)\r\n",
        "\r\n",
        "    return [tokens, masks, segments], targets\r\n",
        "\r\n",
        "# convert_data 함수를 불러오는 함수를 정의\r\n",
        "def load_data(pandas_dataframe):\r\n",
        "    data_df = pandas_dataframe\r\n",
        "    data_df[DATA_COLUMN] = data_df[DATA_COLUMN].astype(str)\r\n",
        "    data_df[LABEL_COLUMN] = data_df[LABEL_COLUMN].astype(int)\r\n",
        "    data_x, data_y = convert_data(data_df)\r\n",
        "    return data_x, data_y"
      ],
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lg61oVflcsjY",
        "outputId": "f0ddd618-7ded-464b-a6e2-8bfc9b6be137"
      },
      "source": [
        "# 긍부정 문장을 포함하고 있는 칼럼\r\n",
        "DATA_COLUMN = \"Sentence\"\r\n",
        "# 긍정인지 부정인지를 (1=긍정,0=부정) 포함하고 있는 칼럼\r\n",
        "LABEL_COLUMN = \"label\"\r\n",
        "\r\n",
        "# train 데이터를 버트 인풋에 맞게 변환\r\n",
        "train_x, train_y = load_data(train)\r\n",
        "\r\n",
        "# validation 데이터를 버트 인풋에 맞게 변환\r\n",
        "validation_x, validation_y = load_data(val)\r\n",
        "\r\n",
        "# test 데이터를 버트 인풋에 맞게 변환\r\n",
        "test_x, test_y = load_data(test)"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "  0%|          | 0/127500 [00:00<?, ?it/s]Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "/usr/local/lib/python3.6/dist-packages/transformers/tokenization_utils_base.py:2179: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n",
            "100%|██████████| 127500/127500 [00:26<00:00, 4834.53it/s]\n",
            "100%|██████████| 22500/22500 [00:04<00:00, 4924.72it/s]\n",
            "100%|██████████| 50000/50000 [00:10<00:00, 4757.99it/s]\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "s1OtC62JaI8S"
      },
      "source": [
        "#### model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 477,
          "referenced_widgets": [
            "3ea9fbd483534ddba88a4cac260b09f5",
            "af49b9c78d9048d685d0981e56652ee5",
            "2429b04ba65449ef8606683302ffc7b6",
            "9dcdafc684344e58af91af7702d3b0f0",
            "4568f71f330d4cfa854ca1d800e8d31a",
            "a9ce680655ce4422b83b6b7408ca5da7",
            "9e77ac4996744c4e9aaa9c64e7242433",
            "eadcfa07fa3d40349845bd44497c6795",
            "7ca03843cd7d4789ad324e522beb5f72",
            "9944a24dd4be4ea8a00663801c2a0c1f",
            "5ab9ff7245aa44f69ac5beb59a254c95",
            "9463780b122942ce9f4c76f6e2e43e53",
            "17f30439f67c4f4a88964d83927f88a5",
            "381086a51a3a4b7a83d8afd7edf2dcff",
            "922e8f80f7564f1b8f8f8885fcbe7d6b",
            "9420ccb76c264550a7c230b27fc09772"
          ]
        },
        "id": "a_YlM23laHHi",
        "outputId": "2b6cdd9d-7c9b-4307-dda2-d4ab8763135e"
      },
      "source": [
        "model = TFBertModel.from_pretrained(\"monologg/kobert\", from_pt=True)\r\n",
        "# 토큰 인풋, 마스크 인풋, 세그먼트 인풋 정의\r\n",
        "token_inputs = tf.keras.layers.Input((SEQ_LEN,), dtype=tf.int32, name='input_word_ids')\r\n",
        "mask_inputs = tf.keras.layers.Input((SEQ_LEN,), dtype=tf.int32, name='input_masks')\r\n",
        "segment_inputs = tf.keras.layers.Input((SEQ_LEN,), dtype=tf.int32, name='input_segment')\r\n",
        "# 인풋이 [토큰, 마스크, 세그먼트]인 모델 정의\r\n",
        "bert_outputs = model([token_inputs, mask_inputs, segment_inputs])"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "3ea9fbd483534ddba88a4cac260b09f5",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=426.0, style=ProgressStyle(description_…"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "7ca03843cd7d4789ad324e522beb5f72",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=368792146.0, style=ProgressStyle(descri…"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "All PyTorch model weights were used when initializing TFBertModel.\n",
            "\n",
            "All the weights of TFBertModel were initialized from the PyTorch model.\n",
            "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFBertModel for predictions without further training.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:AutoGraph could not transform <bound method Socket.send of <zmq.sugar.socket.Socket object at 0x7fcda52e6660>> and will run it as-is.\n",
            "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
            "Cause: <cyfunction Socket.send at 0x7fcdc0b2ce58> is not a module, class, method, function, traceback, frame, or code object\n",
            "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
            "WARNING: AutoGraph could not transform <bound method Socket.send of <zmq.sugar.socket.Socket object at 0x7fcda52e6660>> and will run it as-is.\n",
            "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
            "Cause: <cyfunction Socket.send at 0x7fcdc0b2ce58> is not a module, class, method, function, traceback, frame, or code object\n",
            "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:AutoGraph could not transform <function wrap at 0x7fcdbe4c08c8> and will run it as-is.\n",
            "Cause: while/else statement not yet supported\n",
            "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING: AutoGraph could not transform <function wrap at 0x7fcdbe4c08c8> and will run it as-is.\n",
            "Cause: while/else statement not yet supported\n",
            "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "886IbYsoaMAx",
        "outputId": "7de77f7b-7614-490e-9db5-fa01177856fd"
      },
      "source": [
        "bert_outputs"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "TFBaseModelOutputWithPooling([('last_hidden_state',\n",
              "                               <KerasTensor: shape=(None, 128, 768) dtype=float32 (created by layer 'tf_bert_model')>),\n",
              "                              ('pooler_output',\n",
              "                               <KerasTensor: shape=(None, 768) dtype=float32 (created by layer 'tf_bert_model')>)])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TM85m8neaNzZ"
      },
      "source": [
        "bert_outputs = bert_outputs[1]"
      ],
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HAnLF__laPoc"
      },
      "source": [
        "# Rectified Adam \r\n",
        "import tensorflow_addons as tfa\r\n",
        "opt = tfa.optimizers.RectifiedAdam(lr=1.0e-5, total_steps = ITERATIONS*EPOCHS, warmup_proportion=0.15, min_lr=1e-5, epsilon=1e-08, clipnorm=1.0)"
      ],
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7IUrq_cwaPsi"
      },
      "source": [
        "sentiment_drop = tf.keras.layers.Dropout(0.5)(bert_outputs)\r\n",
        "sentiment_first = tf.keras.layers.Dense(1, activation='sigmoid', kernel_initializer=tf.keras.initializers.TruncatedNormal(stddev=0.02))(sentiment_drop)\r\n",
        "sentiment_model = tf.keras.Model([token_inputs, mask_inputs, segment_inputs], sentiment_first)\r\n",
        "sentiment_model.compile(optimizer=opt, loss=tf.keras.losses.BinaryCrossentropy(), metrics = ['accuracy'])"
      ],
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kpZg7TCQaPvl",
        "outputId": "f32f6210-ca81-4046-db08-72ec6f42cf14"
      },
      "source": [
        "sentiment_model.summary()"
      ],
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"model\"\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "input_word_ids (InputLayer)     [(None, 128)]        0                                            \n",
            "__________________________________________________________________________________________________\n",
            "input_masks (InputLayer)        [(None, 128)]        0                                            \n",
            "__________________________________________________________________________________________________\n",
            "input_segment (InputLayer)      [(None, 128)]        0                                            \n",
            "__________________________________________________________________________________________________\n",
            "tf_bert_model (TFBertModel)     TFBaseModelOutputWit 92186880    input_word_ids[0][0]             \n",
            "                                                                 input_masks[0][0]                \n",
            "                                                                 input_segment[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "dropout_37 (Dropout)            (None, 768)          0           tf_bert_model[0][1]              \n",
            "__________________________________________________________________________________________________\n",
            "dense (Dense)                   (None, 1)            769         dropout_37[0][0]                 \n",
            "==================================================================================================\n",
            "Total params: 92,187,649\n",
            "Trainable params: 92,187,649\n",
            "Non-trainable params: 0\n",
            "__________________________________________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "j9cRSfT1ad6f"
      },
      "source": [
        "#### train"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "p9zBTNnKaPyP",
        "outputId": "fe1c64f9-6fb4-4350-94f8-467049e08ad5"
      },
      "source": [
        "sentiment_model.fit(train_x, train_y, epochs=EPOCHS, shuffle=True, batch_size=BATCH_SIZE, validation_data=(validation_x, validation_y))"
      ],
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/5\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n",
            "The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n",
            "The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n",
            "The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "3985/3985 [==============================] - ETA: 0s - loss: 0.6130 - accuracy: 0.6101"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n",
            "The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r3985/3985 [==============================] - 1429s 345ms/step - loss: 0.6129 - accuracy: 0.6101 - val_loss: 0.3391 - val_accuracy: 0.8520\n",
            "Epoch 2/5\n",
            "3985/3985 [==============================] - 1366s 343ms/step - loss: 0.3170 - accuracy: 0.8655 - val_loss: 0.2962 - val_accuracy: 0.8757\n",
            "Epoch 3/5\n",
            "3985/3985 [==============================] - 1360s 341ms/step - loss: 0.2591 - accuracy: 0.8942 - val_loss: 0.2891 - val_accuracy: 0.8808\n",
            "Epoch 4/5\n",
            "3985/3985 [==============================] - 1371s 344ms/step - loss: 0.2211 - accuracy: 0.9120 - val_loss: 0.2968 - val_accuracy: 0.8858\n",
            "Epoch 5/5\n",
            "3985/3985 [==============================] - 1371s 344ms/step - loss: 0.1831 - accuracy: 0.9291 - val_loss: 0.3075 - val_accuracy: 0.8855\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7fcd04f307b8>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 27
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xrIeRT2iaoFI"
      },
      "source": [
        "#### prediect"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IWPLkV-iajEk"
      },
      "source": [
        "def predict_convert_data(data_df):\r\n",
        "    global tokenizer\r\n",
        "    tokens, masks, segments = [], [], []\r\n",
        "    \r\n",
        "    for i in tqdm(range(len(data_df))):\r\n",
        "\r\n",
        "        token = tokenizer.encode(data_df[DATA_COLUMN][i], max_length=SEQ_LEN, pad_to_max_length=True)\r\n",
        "        num_zeros = token.count(0)\r\n",
        "        mask = [1]*(SEQ_LEN-num_zeros) + [0]*num_zeros\r\n",
        "        segment = [0]*SEQ_LEN\r\n",
        "\r\n",
        "        tokens.append(token)\r\n",
        "        segments.append(segment)\r\n",
        "        masks.append(mask)\r\n",
        "\r\n",
        "    tokens = np.array(tokens)\r\n",
        "    masks = np.array(masks)\r\n",
        "    segments = np.array(segments)\r\n",
        "    return [tokens, masks, segments]\r\n",
        "\r\n",
        "def predict_load_data(pandas_dataframe):\r\n",
        "    data_df = pandas_dataframe\r\n",
        "    data_df[DATA_COLUMN] = data_df[DATA_COLUMN].astype(str)\r\n",
        "    data_x = predict_convert_data(data_df)\r\n",
        "    return data_x"
      ],
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qZi11MHVauiq"
      },
      "source": [
        "#### test"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "c_OVrtSiaqc8",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8117846a-f96f-43f9-9a83-53fe3599583e"
      },
      "source": [
        "test_set = predict_load_data(test)"
      ],
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "  0%|          | 0/50000 [00:00<?, ?it/s]/usr/local/lib/python3.6/dist-packages/transformers/tokenization_utils_base.py:2179: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n",
            "100%|██████████| 50000/50000 [00:09<00:00, 5152.07it/s]\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3kL8mWqrasWk",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3ae3bd36-0a7d-4668-e863-d015a6cab95c"
      },
      "source": [
        "test_set"
      ],
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[array([[   2,  517, 5515, ...,    1,    1,    1],\n",
              "        [   2,  650,  278, ...,    1,    1,    1],\n",
              "        [   2, 2145, 6844, ...,    1,    1,    1],\n",
              "        ...,\n",
              "        [   2, 1212, 5859, ...,    1,    1,    1],\n",
              "        [   2, 4069, 2420, ...,    1,    1,    1],\n",
              "        [   2, 1914, 5760, ...,    1,    1,    1]]),\n",
              " array([[1, 1, 1, ..., 1, 1, 1],\n",
              "        [1, 1, 1, ..., 1, 1, 1],\n",
              "        [1, 1, 1, ..., 1, 1, 1],\n",
              "        ...,\n",
              "        [1, 1, 1, ..., 1, 1, 1],\n",
              "        [1, 1, 1, ..., 1, 1, 1],\n",
              "        [1, 1, 1, ..., 1, 1, 1]]),\n",
              " array([[0, 0, 0, ..., 0, 0, 0],\n",
              "        [0, 0, 0, ..., 0, 0, 0],\n",
              "        [0, 0, 0, ..., 0, 0, 0],\n",
              "        ...,\n",
              "        [0, 0, 0, ..., 0, 0, 0],\n",
              "        [0, 0, 0, ..., 0, 0, 0],\n",
              "        [0, 0, 0, ..., 0, 0, 0]])]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 30
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GqmV0yZbawwF",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a8de2c9b-04e1-47b7-a121-52c1658e3675"
      },
      "source": [
        "preds = sentiment_model.predict(test_set)"
      ],
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n",
            "The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7qRViwtMa1D2",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "452fd583-2266-4e39-c9db-fb8fc3f8b81d"
      },
      "source": [
        "from sklearn.metrics import classification_report\r\n",
        "y_true = test['label']\r\n",
        "# F1 Score 확인\r\n",
        "print(classification_report(y_true, np.round(preds,0)))"
      ],
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.87      0.90      0.89     24827\n",
            "           1       0.90      0.87      0.88     25173\n",
            "\n",
            "    accuracy                           0.89     50000\n",
            "   macro avg       0.89      0.89      0.89     50000\n",
            "weighted avg       0.89      0.89      0.89     50000\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "b7Rq7I5na4Iy"
      },
      "source": [
        "import logging\r\n",
        "tf.get_logger().setLevel(logging.ERROR)"
      ],
      "execution_count": 33,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RaCfkio1a5Fm"
      },
      "source": [
        "#### competition data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3jyt01kPa7i-",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6a5abb81-bc78-4370-c09e-fcfa16de2f8b"
      },
      "source": [
        "cptt_test = pd.read_csv(DATA_PATH + \"ko_data.csv\", sep=',', encoding='CP949')\r\n",
        "print(cptt_test.shape)"
      ],
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(11187, 2)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "p4Hg4zXTbADI",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 202
        },
        "outputId": "594e2d9f-0ffa-45a8-fd92-78f45b91949c"
      },
      "source": [
        "cptt_test[:5]"
      ],
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Id</th>\n",
              "      <th>Sentence</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>정말 많이 울었던 영화입니다.</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>시간 낭비예요.</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2</td>\n",
              "      <td>포스터를 저렇게밖에 만들지 못했던 제작자의 소심함에 침을 뱉고 싶다.</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>3</td>\n",
              "      <td>지금 봐도 재미있는 영화!!! 코믹과 감동!!! 그리고 요리!!!</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>4</td>\n",
              "      <td>이걸 영화로 만드는 거야?얼마나 가는지 보자.</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   Id                                Sentence\n",
              "0   0                        정말 많이 울었던 영화입니다.\n",
              "1   1                                시간 낭비예요.\n",
              "2   2  포스터를 저렇게밖에 만들지 못했던 제작자의 소심함에 침을 뱉고 싶다.\n",
              "3   3    지금 봐도 재미있는 영화!!! 코믹과 감동!!! 그리고 요리!!!\n",
              "4   4               이걸 영화로 만드는 거야?얼마나 가는지 보자."
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 35
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aA1SsQAdew9T",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c1a2eea5-f10d-43c5-8c76-0f5c4a86c9b5"
      },
      "source": [
        "cptt_set = predict_load_data(cptt_test)"
      ],
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "  0%|          | 0/11187 [00:00<?, ?it/s]/usr/local/lib/python3.6/dist-packages/transformers/tokenization_utils_base.py:2179: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n",
            "100%|██████████| 11187/11187 [00:02<00:00, 5536.78it/s]\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iCm1hNCwe7sH"
      },
      "source": [
        "cptt_predict_label = sentiment_model.predict(cptt_set)"
      ],
      "execution_count": 37,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OIv4lyvBfFHf",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "cd5c0a21-80f7-4341-fff3-b53058058ddd"
      },
      "source": [
        "print(cptt_predict_label)"
      ],
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[0.9894533 ]\n",
            " [0.00461311]\n",
            " [0.86748224]\n",
            " ...\n",
            " [0.9942637 ]\n",
            " [0.86864173]\n",
            " [0.1470014 ]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Onhuf1Cn8Eua",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 202
        },
        "outputId": "9e2d7e57-0da8-4da5-b3c4-5f312433ae7e"
      },
      "source": [
        "df0 = pd.DataFrame(data=cptt_test['Id'], columns=['Id'])\r\n",
        "df1 = pd.DataFrame(data=np.round(cptt_predict_label,0),columns=['Predicted'])\r\n",
        "\r\n",
        "final_predicted = pd.concat([df0, df1], axis=1)\r\n",
        "final_predicted[:5]"
      ],
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Id</th>\n",
              "      <th>Predicted</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>3</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>4</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   Id  Predicted\n",
              "0   0        1.0\n",
              "1   1        0.0\n",
              "2   2        1.0\n",
              "3   3        1.0\n",
              "4   4        0.0"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 39
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "t20sRu7saN4g"
      },
      "source": [
        "final_predicted.to_csv(DATA_PATH + 'sample.csv', index=False)"
      ],
      "execution_count": 40,
      "outputs": []
    }
  ]
}