{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "naver sentiment movie corpus_kobert_submit",
      "provenance": [],
      "collapsed_sections": [],
      "machine_shape": "hm",
      "authorship_tag": "ABX9TyNFA3h3Rmy9SSy8isN4HIDh",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "ed76673e8c8e43148b0fae79a05695d1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_94b50d555ea44f1ab0b1fc1ab53f70eb",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_b2efdab8cae44583b39f81ec6c523a42",
              "IPY_MODEL_3a44d917fd944b0384145df42932f027"
            ]
          }
        },
        "94b50d555ea44f1ab0b1fc1ab53f70eb": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "b2efdab8cae44583b39f81ec6c523a42": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_08085b2611bf41b68a882d7cc20020e6",
            "_dom_classes": [],
            "description": "Downloading: 100%",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 371391,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 371391,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_f1dcc2186c8f420783ceda50717a438f"
          }
        },
        "3a44d917fd944b0384145df42932f027": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_27dadbdef8724c959860ab44712fd0f6",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 371k/371k [00:47&lt;00:00, 7.75kB/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_04808c80992441c5b7dd520810014088"
          }
        },
        "08085b2611bf41b68a882d7cc20020e6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "f1dcc2186c8f420783ceda50717a438f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "27dadbdef8724c959860ab44712fd0f6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "04808c80992441c5b7dd520810014088": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "7928e8a2cab74e7c8150878bd091074b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_bfce2442a0f84e52a3ee9f8ce4baf10f",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_12169618add640cc8b936b18b5ffe65d",
              "IPY_MODEL_268e2c471a5a4876b9e056a39c0cbaab"
            ]
          }
        },
        "bfce2442a0f84e52a3ee9f8ce4baf10f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "12169618add640cc8b936b18b5ffe65d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_b96b4283eac0487eaf6f8b1ada95969c",
            "_dom_classes": [],
            "description": "Downloading: 100%",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 77779,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 77779,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_908fa0da4fa04460b1cc503987af25d3"
          }
        },
        "268e2c471a5a4876b9e056a39c0cbaab": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_815663d4ee0c416d9fe5ec0873220ccb",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 77.8k/77.8k [00:10&lt;00:00, 7.63kB/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_7a1bf200cf3c4d06aad57541439d4427"
          }
        },
        "b96b4283eac0487eaf6f8b1ada95969c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "908fa0da4fa04460b1cc503987af25d3": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "815663d4ee0c416d9fe5ec0873220ccb": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "7a1bf200cf3c4d06aad57541439d4427": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/heejin0223/NLPHW/blob/main/naver_sentiment_movie_corpus_kobert_submit.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EkYDNYi5tnAj"
      },
      "source": [
        "###### 데이터 출처 : https://github.com/e9t/nsmc.git   \r\n",
        "###### SKTBrain KoBERT 활용 : https://github.com/monologg/KoBERT-Transformers\r\n",
        "###### 소스참조 :\r\n",
        "- https://github.com/deepseasw/bert-naver-movie-review\r\n",
        "- https://github.com/kimwoonggon/publicservant_AI\r\n",
        "- https://github.com/monologg/KoBERT-Transformers\r\n",
        "- https://github.com/SKTBrain/KoBERT"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "j0b6N3Eitjbb"
      },
      "source": [
        "#### setting"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "c5rg0MFuUQ69",
        "outputId": "e8b42b90-5274-4e56-c731-b8e51c123dcb"
      },
      "source": [
        "import os\r\n",
        "from google.colab import drive\r\n",
        "drive.mount('/content/gdrive/')"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/gdrive/\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VxXNmsCnUbJ-"
      },
      "source": [
        "DATA_PATH = 'gdrive/My Drive/Colab Notebooks/NLP/'\r\n",
        "import sys\r\n",
        "sys.path.append(DATA_PATH)"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nIAoH9KoUkYB",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2502766a-a6e1-4f4f-e379-d026c30a8081"
      },
      "source": [
        "!pip install transformers --quiet"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\u001b[K     |████████████████████████████████| 1.5MB 12.7MB/s \n",
            "\u001b[K     |████████████████████████████████| 2.9MB 52.6MB/s \n",
            "\u001b[K     |████████████████████████████████| 890kB 43.0MB/s \n",
            "\u001b[?25h  Building wheel for sacremoses (setup.py) ... \u001b[?25l\u001b[?25hdone\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "E9dcLG1mUdst"
      },
      "source": [
        "import torch\r\n",
        "import tensorflow as tf\r\n",
        "import numpy as np\r\n",
        "import pandas as pd\r\n",
        "from transformers import *\r\n",
        "import json\r\n",
        "from tqdm import tqdm\r\n",
        "import math\r\n",
        "import urllib.request\r\n",
        "from sklearn.model_selection import train_test_split"
      ],
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cVJXhzn1UjHI",
        "outputId": "d9f7b41c-c5bc-4e87-f230-74359953e4b9"
      },
      "source": [
        "if torch.cuda.is_available():    \r\n",
        "    device = torch.device(\"cuda\")\r\n",
        "    print('There are %d GPU(s) available.' % torch.cuda.device_count())\r\n",
        "    print('We will use the GPU:', torch.cuda.get_device_name(0))\r\n",
        "else:\r\n",
        "    device = torch.device(\"cpu\")\r\n",
        "    print('No GPU available, using the CPU instead.')"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "There are 1 GPU(s) available.\n",
            "We will use the GPU: Tesla V100-SXM2-16GB\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FxClcCvkVJer"
      },
      "source": [
        "#### data\r\n",
        "###### ratings전체로 import하고 이중에서 8:1:1로 training, validation, test 사용"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AsP6xVwjVHMA",
        "outputId": "885d3b49-384e-4481-f88a-0a30fe2f997b"
      },
      "source": [
        "!git clone https://github.com/e9t/nsmc.git"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Cloning into 'nsmc'...\n",
            "remote: Enumerating objects: 14763, done.\u001b[K\n",
            "remote: Total 14763 (delta 0), reused 0 (delta 0), pack-reused 14763\u001b[K\n",
            "Receiving objects: 100% (14763/14763), 56.19 MiB | 19.99 MiB/s, done.\n",
            "Resolving deltas: 100% (1749/1749), done.\n",
            "Checking out files: 100% (14737/14737), done.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "b2KpdqRLZpiL",
        "outputId": "12745065-380f-4dbc-9456-bf4eda78f545"
      },
      "source": [
        "os.listdir('nsmc')"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['raw',\n",
              " 'ratings_test.txt',\n",
              " 'ratings.txt',\n",
              " 'README.md',\n",
              " 'code',\n",
              " '.git',\n",
              " 'synopses.json',\n",
              " 'ratings_train.txt']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0fSjrRPfVOwL",
        "outputId": "29a052e2-8095-45cf-cc95-8478f7c01ea8"
      },
      "source": [
        "total = pd.read_csv(\"nsmc/\"+\"ratings_train.txt\", sep='\\t')\r\n",
        "test = pd.read_csv(\"nsmc/\"+\"ratings_test.txt\", sep='\\t')\r\n",
        "print(total.shape)\r\n",
        "print(test.shape)"
      ],
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(150000, 3)\n",
            "(50000, 3)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        },
        "id": "FAsYLj1xVRRL",
        "outputId": "73df2556-458d-450d-fd7e-260de21473ff"
      },
      "source": [
        "total[:5]"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>document</th>\n",
              "      <th>label</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>8112052</td>\n",
              "      <td>어릴때보고 지금다시봐도 재밌어요ㅋㅋ</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>8132799</td>\n",
              "      <td>디자인을 배우는 학생으로, 외국디자이너와 그들이 일군 전통을 통해 발전해가는 문화산...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>4655635</td>\n",
              "      <td>폴리스스토리 시리즈는 1부터 뉴까지 버릴께 하나도 없음.. 최고.</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>9251303</td>\n",
              "      <td>와.. 연기가 진짜 개쩔구나.. 지루할거라고 생각했는데 몰입해서 봤다.. 그래 이런...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>10067386</td>\n",
              "      <td>안개 자욱한 밤하늘에 떠 있는 초승달 같은 영화.</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "         id                                           document  label\n",
              "0   8112052                                어릴때보고 지금다시봐도 재밌어요ㅋㅋ      1\n",
              "1   8132799  디자인을 배우는 학생으로, 외국디자이너와 그들이 일군 전통을 통해 발전해가는 문화산...      1\n",
              "2   4655635               폴리스스토리 시리즈는 1부터 뉴까지 버릴께 하나도 없음.. 최고.      1\n",
              "3   9251303  와.. 연기가 진짜 개쩔구나.. 지루할거라고 생각했는데 몰입해서 봤다.. 그래 이런...      1\n",
              "4  10067386                        안개 자욱한 밤하늘에 떠 있는 초승달 같은 영화.      1"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 142
        },
        "id": "jy7w4TVoc4ch",
        "outputId": "814f0f0c-42b9-4f44-e0f8-fd9afdddffc5"
      },
      "source": [
        "total.columns = ['id','Sentence','label']\r\n",
        "total[:3]"
      ],
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>Sentence</th>\n",
              "      <th>label</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>9976970</td>\n",
              "      <td>아 더빙.. 진짜 짜증나네요 목소리</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>3819312</td>\n",
              "      <td>흠...포스터보고 초딩영화줄....오버연기조차 가볍지 않구나</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>10265843</td>\n",
              "      <td>너무재밓었다그래서보는것을추천한다</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "         id                           Sentence  label\n",
              "0   9976970                아 더빙.. 진짜 짜증나네요 목소리      0\n",
              "1   3819312  흠...포스터보고 초딩영화줄....오버연기조차 가볍지 않구나      1\n",
              "2  10265843                  너무재밓었다그래서보는것을추천한다      0"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 40
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 142
        },
        "id": "ihWGPJFTJwQr",
        "outputId": "7645e016-dd9a-42c9-ce23-341e8784b992"
      },
      "source": [
        "test.columns = ['id','Sentence','label']\r\n",
        "test[:3]"
      ],
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>Sentence</th>\n",
              "      <th>label</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>6270596</td>\n",
              "      <td>굳 ㅋ</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>9274899</td>\n",
              "      <td>GDNTOPCLASSINTHECLUB</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>8544678</td>\n",
              "      <td>뭐야 이 평점들은.... 나쁘진 않지만 10점 짜리는 더더욱 아니잖아</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "        id                                Sentence  label\n",
              "0  6270596                                     굳 ㅋ      1\n",
              "1  9274899                    GDNTOPCLASSINTHECLUB      0\n",
              "2  8544678  뭐야 이 평점들은.... 나쁘진 않지만 10점 짜리는 더더욱 아니잖아      0"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 41
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Rtbj12ZEG0eM"
      },
      "source": [
        "# class 비율(ratio)을 train / test_temp 유지하며 데이타 나눔\r\n",
        "train, val = train_test_split(total, \r\n",
        "                                    test_size=0.15, \r\n",
        "                                    random_state=42, \r\n",
        "                                    stratify=total.label.values)\r\n"
      ],
      "execution_count": 42,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Sl4s3a9PHYre"
      },
      "source": [
        "train = train.reset_index(drop=True)\r\n",
        "val = val.reset_index(drop=True)"
      ],
      "execution_count": 43,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eKnmAdPCHyKF",
        "outputId": "b6258df3-5ee6-4274-fe27-1dc885ed6451"
      },
      "source": [
        "print(len(train))\r\n",
        "print(len(val))"
      ],
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "127500\n",
            "22500\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "poGtO7k0Vd0S"
      },
      "source": [
        "#### tokenize"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bbqvGS_qZx2j",
        "outputId": "74ebfafc-1367-4c94-d30b-1459b8ce1fdb"
      },
      "source": [
        "!pip install sentencepiece "
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting sentencepiece\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/e5/2d/6d4ca4bef9a67070fa1cac508606328329152b1df10bdf31fb6e4e727894/sentencepiece-0.1.94-cp36-cp36m-manylinux2014_x86_64.whl (1.1MB)\n",
            "\r\u001b[K     |▎                               | 10kB 22.8MB/s eta 0:00:01\r\u001b[K     |▋                               | 20kB 23.2MB/s eta 0:00:01\r\u001b[K     |▉                               | 30kB 17.3MB/s eta 0:00:01\r\u001b[K     |█▏                              | 40kB 9.7MB/s eta 0:00:01\r\u001b[K     |█▌                              | 51kB 11.6MB/s eta 0:00:01\r\u001b[K     |█▊                              | 61kB 11.8MB/s eta 0:00:01\r\u001b[K     |██                              | 71kB 13.3MB/s eta 0:00:01\r\u001b[K     |██▍                             | 81kB 13.2MB/s eta 0:00:01\r\u001b[K     |██▋                             | 92kB 12.3MB/s eta 0:00:01\r\u001b[K     |███                             | 102kB 11.8MB/s eta 0:00:01\r\u001b[K     |███▎                            | 112kB 11.8MB/s eta 0:00:01\r\u001b[K     |███▌                            | 122kB 11.8MB/s eta 0:00:01\r\u001b[K     |███▉                            | 133kB 11.8MB/s eta 0:00:01\r\u001b[K     |████▏                           | 143kB 11.8MB/s eta 0:00:01\r\u001b[K     |████▍                           | 153kB 11.8MB/s eta 0:00:01\r\u001b[K     |████▊                           | 163kB 11.8MB/s eta 0:00:01\r\u001b[K     |█████                           | 174kB 11.8MB/s eta 0:00:01\r\u001b[K     |█████▎                          | 184kB 11.8MB/s eta 0:00:01\r\u001b[K     |█████▋                          | 194kB 11.8MB/s eta 0:00:01\r\u001b[K     |█████▉                          | 204kB 11.8MB/s eta 0:00:01\r\u001b[K     |██████▏                         | 215kB 11.8MB/s eta 0:00:01\r\u001b[K     |██████▌                         | 225kB 11.8MB/s eta 0:00:01\r\u001b[K     |██████▊                         | 235kB 11.8MB/s eta 0:00:01\r\u001b[K     |███████                         | 245kB 11.8MB/s eta 0:00:01\r\u001b[K     |███████▍                        | 256kB 11.8MB/s eta 0:00:01\r\u001b[K     |███████▋                        | 266kB 11.8MB/s eta 0:00:01\r\u001b[K     |████████                        | 276kB 11.8MB/s eta 0:00:01\r\u001b[K     |████████▎                       | 286kB 11.8MB/s eta 0:00:01\r\u001b[K     |████████▌                       | 296kB 11.8MB/s eta 0:00:01\r\u001b[K     |████████▉                       | 307kB 11.8MB/s eta 0:00:01\r\u001b[K     |█████████                       | 317kB 11.8MB/s eta 0:00:01\r\u001b[K     |█████████▍                      | 327kB 11.8MB/s eta 0:00:01\r\u001b[K     |█████████▊                      | 337kB 11.8MB/s eta 0:00:01\r\u001b[K     |██████████                      | 348kB 11.8MB/s eta 0:00:01\r\u001b[K     |██████████▎                     | 358kB 11.8MB/s eta 0:00:01\r\u001b[K     |██████████▋                     | 368kB 11.8MB/s eta 0:00:01\r\u001b[K     |██████████▉                     | 378kB 11.8MB/s eta 0:00:01\r\u001b[K     |███████████▏                    | 389kB 11.8MB/s eta 0:00:01\r\u001b[K     |███████████▌                    | 399kB 11.8MB/s eta 0:00:01\r\u001b[K     |███████████▊                    | 409kB 11.8MB/s eta 0:00:01\r\u001b[K     |████████████                    | 419kB 11.8MB/s eta 0:00:01\r\u001b[K     |████████████▍                   | 430kB 11.8MB/s eta 0:00:01\r\u001b[K     |████████████▋                   | 440kB 11.8MB/s eta 0:00:01\r\u001b[K     |█████████████                   | 450kB 11.8MB/s eta 0:00:01\r\u001b[K     |█████████████▎                  | 460kB 11.8MB/s eta 0:00:01\r\u001b[K     |█████████████▌                  | 471kB 11.8MB/s eta 0:00:01\r\u001b[K     |█████████████▉                  | 481kB 11.8MB/s eta 0:00:01\r\u001b[K     |██████████████                  | 491kB 11.8MB/s eta 0:00:01\r\u001b[K     |██████████████▍                 | 501kB 11.8MB/s eta 0:00:01\r\u001b[K     |██████████████▊                 | 512kB 11.8MB/s eta 0:00:01\r\u001b[K     |███████████████                 | 522kB 11.8MB/s eta 0:00:01\r\u001b[K     |███████████████▎                | 532kB 11.8MB/s eta 0:00:01\r\u001b[K     |███████████████▋                | 542kB 11.8MB/s eta 0:00:01\r\u001b[K     |███████████████▉                | 552kB 11.8MB/s eta 0:00:01\r\u001b[K     |████████████████▏               | 563kB 11.8MB/s eta 0:00:01\r\u001b[K     |████████████████▌               | 573kB 11.8MB/s eta 0:00:01\r\u001b[K     |████████████████▊               | 583kB 11.8MB/s eta 0:00:01\r\u001b[K     |█████████████████               | 593kB 11.8MB/s eta 0:00:01\r\u001b[K     |█████████████████▍              | 604kB 11.8MB/s eta 0:00:01\r\u001b[K     |█████████████████▋              | 614kB 11.8MB/s eta 0:00:01\r\u001b[K     |██████████████████              | 624kB 11.8MB/s eta 0:00:01\r\u001b[K     |██████████████████▏             | 634kB 11.8MB/s eta 0:00:01\r\u001b[K     |██████████████████▌             | 645kB 11.8MB/s eta 0:00:01\r\u001b[K     |██████████████████▉             | 655kB 11.8MB/s eta 0:00:01\r\u001b[K     |███████████████████             | 665kB 11.8MB/s eta 0:00:01\r\u001b[K     |███████████████████▍            | 675kB 11.8MB/s eta 0:00:01\r\u001b[K     |███████████████████▊            | 686kB 11.8MB/s eta 0:00:01\r\u001b[K     |████████████████████            | 696kB 11.8MB/s eta 0:00:01\r\u001b[K     |████████████████████▎           | 706kB 11.8MB/s eta 0:00:01\r\u001b[K     |████████████████████▋           | 716kB 11.8MB/s eta 0:00:01\r\u001b[K     |████████████████████▉           | 727kB 11.8MB/s eta 0:00:01\r\u001b[K     |█████████████████████▏          | 737kB 11.8MB/s eta 0:00:01\r\u001b[K     |█████████████████████▌          | 747kB 11.8MB/s eta 0:00:01\r\u001b[K     |█████████████████████▊          | 757kB 11.8MB/s eta 0:00:01\r\u001b[K     |██████████████████████          | 768kB 11.8MB/s eta 0:00:01\r\u001b[K     |██████████████████████▎         | 778kB 11.8MB/s eta 0:00:01\r\u001b[K     |██████████████████████▋         | 788kB 11.8MB/s eta 0:00:01\r\u001b[K     |███████████████████████         | 798kB 11.8MB/s eta 0:00:01\r\u001b[K     |███████████████████████▏        | 808kB 11.8MB/s eta 0:00:01\r\u001b[K     |███████████████████████▌        | 819kB 11.8MB/s eta 0:00:01\r\u001b[K     |███████████████████████▉        | 829kB 11.8MB/s eta 0:00:01\r\u001b[K     |████████████████████████        | 839kB 11.8MB/s eta 0:00:01\r\u001b[K     |████████████████████████▍       | 849kB 11.8MB/s eta 0:00:01\r\u001b[K     |████████████████████████▊       | 860kB 11.8MB/s eta 0:00:01\r\u001b[K     |█████████████████████████       | 870kB 11.8MB/s eta 0:00:01\r\u001b[K     |█████████████████████████▎      | 880kB 11.8MB/s eta 0:00:01\r\u001b[K     |█████████████████████████▋      | 890kB 11.8MB/s eta 0:00:01\r\u001b[K     |█████████████████████████▉      | 901kB 11.8MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▏     | 911kB 11.8MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▌     | 921kB 11.8MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▊     | 931kB 11.8MB/s eta 0:00:01\r\u001b[K     |███████████████████████████     | 942kB 11.8MB/s eta 0:00:01\r\u001b[K     |███████████████████████████▎    | 952kB 11.8MB/s eta 0:00:01\r\u001b[K     |███████████████████████████▋    | 962kB 11.8MB/s eta 0:00:01\r\u001b[K     |████████████████████████████    | 972kB 11.8MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▏   | 983kB 11.8MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▌   | 993kB 11.8MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▉   | 1.0MB 11.8MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████   | 1.0MB 11.8MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▍  | 1.0MB 11.8MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▊  | 1.0MB 11.8MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████  | 1.0MB 11.8MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▎ | 1.1MB 11.8MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▋ | 1.1MB 11.8MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▉ | 1.1MB 11.8MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▏| 1.1MB 11.8MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▍| 1.1MB 11.8MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▊| 1.1MB 11.8MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 1.1MB 11.8MB/s \n",
            "\u001b[?25hInstalling collected packages: sentencepiece\n",
            "Successfully installed sentencepiece-0.1.94\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GBz2CGqGZ4dC"
      },
      "source": [
        "import logging\r\n",
        "import os\r\n",
        "import unicodedata\r\n",
        "from shutil import copyfile\r\n",
        "\r\n",
        "from transformers import PreTrainedTokenizer\r\n",
        "\r\n",
        "\r\n",
        "logger = logging.getLogger(__name__)\r\n",
        "\r\n",
        "VOCAB_FILES_NAMES = {\"vocab_file\": \"tokenizer_78b3253a26.model\",\r\n",
        "                     \"vocab_txt\": \"vocab.txt\"}\r\n",
        "\r\n",
        "PRETRAINED_VOCAB_FILES_MAP = {\r\n",
        "    \"vocab_file\": {\r\n",
        "        \"monologg/kobert\": \"https://s3.amazonaws.com/models.huggingface.co/bert/monologg/kobert/tokenizer_78b3253a26.model\",\r\n",
        "        \"monologg/kobert-lm\": \"https://s3.amazonaws.com/models.huggingface.co/bert/monologg/kobert-lm/tokenizer_78b3253a26.model\",\r\n",
        "        \"monologg/distilkobert\": \"https://s3.amazonaws.com/models.huggingface.co/bert/monologg/distilkobert/tokenizer_78b3253a26.model\"\r\n",
        "    },\r\n",
        "    \"vocab_txt\": {\r\n",
        "        \"monologg/kobert\": \"https://s3.amazonaws.com/models.huggingface.co/bert/monologg/kobert/vocab.txt\",\r\n",
        "        \"monologg/kobert-lm\": \"https://s3.amazonaws.com/models.huggingface.co/bert/monologg/kobert-lm/vocab.txt\",\r\n",
        "        \"monologg/distilkobert\": \"https://s3.amazonaws.com/models.huggingface.co/bert/monologg/distilkobert/vocab.txt\"\r\n",
        "    }\r\n",
        "}\r\n",
        "\r\n",
        "PRETRAINED_POSITIONAL_EMBEDDINGS_SIZES = {\r\n",
        "    \"monologg/kobert\": 512,\r\n",
        "    \"monologg/kobert-lm\": 512,\r\n",
        "    \"monologg/distilkobert\": 512\r\n",
        "}\r\n",
        "\r\n",
        "PRETRAINED_INIT_CONFIGURATION = {\r\n",
        "    \"monologg/kobert\": {\"do_lower_case\": False},\r\n",
        "    \"monologg/kobert-lm\": {\"do_lower_case\": False},\r\n",
        "    \"monologg/distilkobert\": {\"do_lower_case\": False}\r\n",
        "}\r\n",
        "\r\n",
        "SPIECE_UNDERLINE = u'▁'\r\n",
        "\r\n",
        "\r\n",
        "class KoBertTokenizer(PreTrainedTokenizer):\r\n",
        "    \"\"\"\r\n",
        "        SentencePiece based tokenizer. Peculiarities:\r\n",
        "            - requires `SentencePiece <https://github.com/google/sentencepiece>`_\r\n",
        "    \"\"\"\r\n",
        "    vocab_files_names = VOCAB_FILES_NAMES\r\n",
        "    pretrained_vocab_files_map = PRETRAINED_VOCAB_FILES_MAP\r\n",
        "    pretrained_init_configuration = PRETRAINED_INIT_CONFIGURATION\r\n",
        "    max_model_input_sizes = PRETRAINED_POSITIONAL_EMBEDDINGS_SIZES\r\n",
        "\r\n",
        "    def __init__(\r\n",
        "            self,\r\n",
        "            vocab_file,\r\n",
        "            vocab_txt,\r\n",
        "            do_lower_case=False,\r\n",
        "            remove_space=True,\r\n",
        "            keep_accents=False,\r\n",
        "            unk_token=\"[UNK]\",\r\n",
        "            sep_token=\"[SEP]\",\r\n",
        "            pad_token=\"[PAD]\",\r\n",
        "            cls_token=\"[CLS]\",\r\n",
        "            mask_token=\"[MASK]\",\r\n",
        "            **kwargs):\r\n",
        "        super().__init__(\r\n",
        "            unk_token=unk_token,\r\n",
        "            sep_token=sep_token,\r\n",
        "            pad_token=pad_token,\r\n",
        "            cls_token=cls_token,\r\n",
        "            mask_token=mask_token,\r\n",
        "            **kwargs\r\n",
        "        )\r\n",
        "\r\n",
        "        # Build vocab\r\n",
        "        self.token2idx = dict()\r\n",
        "        self.idx2token = []\r\n",
        "        with open(vocab_txt, 'r', encoding='utf-8') as f:\r\n",
        "            for idx, token in enumerate(f):\r\n",
        "                token = token.strip()\r\n",
        "                self.token2idx[token] = idx\r\n",
        "                self.idx2token.append(token)\r\n",
        "\r\n",
        "        try:\r\n",
        "            import sentencepiece as spm\r\n",
        "        except ImportError:\r\n",
        "            logger.warning(\"You need to install SentencePiece to use KoBertTokenizer: https://github.com/google/sentencepiece\"\r\n",
        "                           \"pip install sentencepiece\")\r\n",
        "\r\n",
        "        self.do_lower_case = do_lower_case\r\n",
        "        self.remove_space = remove_space\r\n",
        "        self.keep_accents = keep_accents\r\n",
        "        self.vocab_file = vocab_file\r\n",
        "        self.vocab_txt = vocab_txt\r\n",
        "\r\n",
        "        self.sp_model = spm.SentencePieceProcessor()\r\n",
        "        self.sp_model.Load(vocab_file)\r\n",
        "\r\n",
        "    @property\r\n",
        "    def vocab_size(self):\r\n",
        "        return len(self.idx2token)\r\n",
        "\r\n",
        "    def get_vocab(self):\r\n",
        "        return dict(self.token2idx, **self.added_tokens_encoder)\r\n",
        "\r\n",
        "    def __getstate__(self):\r\n",
        "        state = self.__dict__.copy()\r\n",
        "        state[\"sp_model\"] = None\r\n",
        "        return state\r\n",
        "\r\n",
        "    def __setstate__(self, d):\r\n",
        "        self.__dict__ = d\r\n",
        "        try:\r\n",
        "            import sentencepiece as spm\r\n",
        "        except ImportError:\r\n",
        "            logger.warning(\"You need to install SentencePiece to use KoBertTokenizer: https://github.com/google/sentencepiece\"\r\n",
        "                           \"pip install sentencepiece\")\r\n",
        "        self.sp_model = spm.SentencePieceProcessor()\r\n",
        "        self.sp_model.Load(self.vocab_file)\r\n",
        "\r\n",
        "    def preprocess_text(self, inputs):\r\n",
        "        if self.remove_space:\r\n",
        "            outputs = \" \".join(inputs.strip().split())\r\n",
        "        else:\r\n",
        "            outputs = inputs\r\n",
        "        outputs = outputs.replace(\"``\", '\"').replace(\"''\", '\"')\r\n",
        "\r\n",
        "        if not self.keep_accents:\r\n",
        "            outputs = unicodedata.normalize('NFKD', outputs)\r\n",
        "            outputs = \"\".join([c for c in outputs if not unicodedata.combining(c)])\r\n",
        "        if self.do_lower_case:\r\n",
        "            outputs = outputs.lower()\r\n",
        "\r\n",
        "        return outputs\r\n",
        "\r\n",
        "    def _tokenize(self, text, return_unicode=True, sample=False):\r\n",
        "        \"\"\" Tokenize a string. \"\"\"\r\n",
        "        text = self.preprocess_text(text)\r\n",
        "\r\n",
        "        if not sample:\r\n",
        "            pieces = self.sp_model.EncodeAsPieces(text)\r\n",
        "        else:\r\n",
        "            pieces = self.sp_model.SampleEncodeAsPieces(text, 64, 0.1)\r\n",
        "        new_pieces = []\r\n",
        "        for piece in pieces:\r\n",
        "            if len(piece) > 1 and piece[-1] == str(\",\") and piece[-2].isdigit():\r\n",
        "                cur_pieces = self.sp_model.EncodeAsPieces(piece[:-1].replace(SPIECE_UNDERLINE, \"\"))\r\n",
        "                if piece[0] != SPIECE_UNDERLINE and cur_pieces[0][0] == SPIECE_UNDERLINE:\r\n",
        "                    if len(cur_pieces[0]) == 1:\r\n",
        "                        cur_pieces = cur_pieces[1:]\r\n",
        "                    else:\r\n",
        "                        cur_pieces[0] = cur_pieces[0][1:]\r\n",
        "                cur_pieces.append(piece[-1])\r\n",
        "                new_pieces.extend(cur_pieces)\r\n",
        "            else:\r\n",
        "                new_pieces.append(piece)\r\n",
        "\r\n",
        "        return new_pieces\r\n",
        "\r\n",
        "    def _convert_token_to_id(self, token):\r\n",
        "        \"\"\" Converts a token (str/unicode) in an id using the vocab. \"\"\"\r\n",
        "        return self.token2idx.get(token, self.token2idx[self.unk_token])\r\n",
        "\r\n",
        "    def _convert_id_to_token(self, index, return_unicode=True):\r\n",
        "        \"\"\"Converts an index (integer) in a token (string/unicode) using the vocab.\"\"\"\r\n",
        "        return self.idx2token[index]\r\n",
        "\r\n",
        "    def convert_tokens_to_string(self, tokens):\r\n",
        "        \"\"\"Converts a sequence of tokens (strings for sub-words) in a single string.\"\"\"\r\n",
        "        out_string = \"\".join(tokens).replace(SPIECE_UNDERLINE, \" \").strip()\r\n",
        "        return out_string\r\n",
        "\r\n",
        "    def build_inputs_with_special_tokens(self, token_ids_0, token_ids_1=None):\r\n",
        "        \"\"\"\r\n",
        "        Build model inputs from a sequence or a pair of sequence for sequence classification tasks\r\n",
        "        by concatenating and adding special tokens.\r\n",
        "        A KoBERT sequence has the following format:\r\n",
        "            single sequence: [CLS] X [SEP]\r\n",
        "            pair of sequences: [CLS] A [SEP] B [SEP]\r\n",
        "        \"\"\"\r\n",
        "        if token_ids_1 is None:\r\n",
        "            return [self.cls_token_id] + token_ids_0 + [self.sep_token_id]\r\n",
        "        cls = [self.cls_token_id]\r\n",
        "        sep = [self.sep_token_id]\r\n",
        "        return cls + token_ids_0 + sep + token_ids_1 + sep\r\n",
        "\r\n",
        "    def get_special_tokens_mask(self, token_ids_0, token_ids_1=None, already_has_special_tokens=False):\r\n",
        "        \"\"\"\r\n",
        "        Retrieves sequence ids from a token list that has no special tokens added. This method is called when adding\r\n",
        "        special tokens using the tokenizer ``prepare_for_model`` or ``encode_plus`` methods.\r\n",
        "        Args:\r\n",
        "            token_ids_0: list of ids (must not contain special tokens)\r\n",
        "            token_ids_1: Optional list of ids (must not contain special tokens), necessary when fetching sequence ids\r\n",
        "                for sequence pairs\r\n",
        "            already_has_special_tokens: (default False) Set to True if the token list is already formated with\r\n",
        "                special tokens for the model\r\n",
        "        Returns:\r\n",
        "            A list of integers in the range [0, 1]: 0 for a special token, 1 for a sequence token.\r\n",
        "        \"\"\"\r\n",
        "\r\n",
        "        if already_has_special_tokens:\r\n",
        "            if token_ids_1 is not None:\r\n",
        "                raise ValueError(\r\n",
        "                    \"You should not supply a second sequence if the provided sequence of \"\r\n",
        "                    \"ids is already formated with special tokens for the model.\"\r\n",
        "                )\r\n",
        "            return list(map(lambda x: 1 if x in [self.sep_token_id, self.cls_token_id] else 0, token_ids_0))\r\n",
        "\r\n",
        "        if token_ids_1 is not None:\r\n",
        "            return [1] + ([0] * len(token_ids_0)) + [1] + ([0] * len(token_ids_1)) + [1]\r\n",
        "        return [1] + ([0] * len(token_ids_0)) + [1]\r\n",
        "\r\n",
        "    def create_token_type_ids_from_sequences(self, token_ids_0, token_ids_1=None):\r\n",
        "        \"\"\"\r\n",
        "        Creates a mask from the two sequences passed to be used in a sequence-pair classification task.\r\n",
        "        A KoBERT sequence pair mask has the following format:\r\n",
        "        0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1\r\n",
        "        | first sequence    | second sequence\r\n",
        "        if token_ids_1 is None, only returns the first portion of the mask (0's).\r\n",
        "        \"\"\"\r\n",
        "        sep = [self.sep_token_id]\r\n",
        "        cls = [self.cls_token_id]\r\n",
        "        if token_ids_1 is None:\r\n",
        "            return len(cls + token_ids_0 + sep) * [0]\r\n",
        "        return len(cls + token_ids_0 + sep) * [0] + len(token_ids_1 + sep) * [1]\r\n",
        "\r\n",
        "    def save_vocabulary(self, save_directory):\r\n",
        "        \"\"\" Save the sentencepiece vocabulary (copy original file) and special tokens file\r\n",
        "            to a directory.\r\n",
        "        \"\"\"\r\n",
        "        if not os.path.isdir(save_directory):\r\n",
        "            logger.error(\"Vocabulary path ({}) should be a directory\".format(save_directory))\r\n",
        "            return\r\n",
        "\r\n",
        "        # 1. Save sentencepiece model\r\n",
        "        out_vocab_model = os.path.join(save_directory, VOCAB_FILES_NAMES[\"vocab_file\"])\r\n",
        "\r\n",
        "        if os.path.abspath(self.vocab_file) != os.path.abspath(out_vocab_model):\r\n",
        "            copyfile(self.vocab_file, out_vocab_model)\r\n",
        "\r\n",
        "        # 2. Save vocab.txt\r\n",
        "        index = 0\r\n",
        "        out_vocab_txt = os.path.join(save_directory, VOCAB_FILES_NAMES[\"vocab_txt\"])\r\n",
        "        with open(out_vocab_txt, \"w\", encoding=\"utf-8\") as writer:\r\n",
        "            for token, token_index in sorted(self.token2idx.items(), key=lambda kv: kv[1]):\r\n",
        "                if index != token_index:\r\n",
        "                    logger.warning(\r\n",
        "                        \"Saving vocabulary to {}: vocabulary indices are not consecutive.\"\r\n",
        "                        \" Please check that the vocabulary is not corrupted!\".format(out_vocab_txt)\r\n",
        "                    )\r\n",
        "                    index = token_index\r\n",
        "                writer.write(token + \"\\n\")\r\n",
        "                index += 1\r\n",
        "\r\n",
        "        return out_vocab_model, out_vocab_txt"
      ],
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 117,
          "referenced_widgets": [
            "ed76673e8c8e43148b0fae79a05695d1",
            "94b50d555ea44f1ab0b1fc1ab53f70eb",
            "b2efdab8cae44583b39f81ec6c523a42",
            "3a44d917fd944b0384145df42932f027",
            "08085b2611bf41b68a882d7cc20020e6",
            "f1dcc2186c8f420783ceda50717a438f",
            "27dadbdef8724c959860ab44712fd0f6",
            "04808c80992441c5b7dd520810014088",
            "7928e8a2cab74e7c8150878bd091074b",
            "bfce2442a0f84e52a3ee9f8ce4baf10f",
            "12169618add640cc8b936b18b5ffe65d",
            "268e2c471a5a4876b9e056a39c0cbaab",
            "b96b4283eac0487eaf6f8b1ada95969c",
            "908fa0da4fa04460b1cc503987af25d3",
            "815663d4ee0c416d9fe5ec0873220ccb",
            "7a1bf200cf3c4d06aad57541439d4427"
          ]
        },
        "id": "rn0_7wyhZ9Ht",
        "outputId": "e3319686-7164-4250-e377-d72ddc8d79dd"
      },
      "source": [
        "tokenizer = KoBertTokenizer.from_pretrained('monologg/kobert')"
      ],
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "ed76673e8c8e43148b0fae79a05695d1",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=371391.0, style=ProgressStyle(descripti…"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "7928e8a2cab74e7c8150878bd091074b",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=77779.0, style=ProgressStyle(descriptio…"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NRnbIBZTQTaM"
      },
      "source": [
        "SEQ_LEN = 128\r\n",
        "BATCH_SIZE = 32\r\n",
        "EPOCHS = 5\r\n",
        "ITERATIONS = math.ceil(len(train)//BATCH_SIZE)"
      ],
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Y34s0WKvVvAS"
      },
      "source": [
        "def convert_data(data_df):\r\n",
        "    global tokenizer\r\n",
        "    \r\n",
        "#    SEQ_LEN = MAX_LEN    \r\n",
        "    \r\n",
        "    tokens, masks, segments, targets = [], [], [], []\r\n",
        "    \r\n",
        "    for i in tqdm(range(len(data_df))):\r\n",
        "        # 토큰 : 문장을 토큰화한 값\r\n",
        "        token = tokenizer.encode(data_df[DATA_COLUMN][i], max_length=SEQ_LEN, pad_to_max_length=True)\r\n",
        "       \r\n",
        "        # 마스크 : 토큰화한 문장 중 패딩은 0, 문자는 1\r\n",
        "        num_zeros = token.count(0)\r\n",
        "        mask = [1]*(SEQ_LEN-num_zeros) + [0]*num_zeros\r\n",
        "        \r\n",
        "        # 세그먼트 : 문장의 전후관계 구분 (단일문장은 전후관계 없으므로 모두 0)\r\n",
        "        segment = [0]*SEQ_LEN\r\n",
        "\r\n",
        "        # 버트 인풋값을 각각 tokens,masks, segments에 저장\r\n",
        "        tokens.append(token)\r\n",
        "        masks.append(mask)\r\n",
        "        segments.append(segment)\r\n",
        "        \r\n",
        "        # 정답label을 targets에 저장\r\n",
        "        targets.append(data_df[LABEL_COLUMN][i])\r\n",
        "\r\n",
        "    # tokens, masks, segments, targets를 numpy array로 지정    \r\n",
        "    tokens = np.array(tokens)\r\n",
        "    masks = np.array(masks)\r\n",
        "    segments = np.array(segments)\r\n",
        "    targets = np.array(targets)\r\n",
        "\r\n",
        "    return [tokens, masks, segments], targets\r\n",
        "\r\n",
        "# convert_data 함수를 불러오는 함수를 정의\r\n",
        "def load_data(pandas_dataframe):\r\n",
        "    data_df = pandas_dataframe\r\n",
        "    data_df[DATA_COLUMN] = data_df[DATA_COLUMN].astype(str)\r\n",
        "    data_df[LABEL_COLUMN] = data_df[LABEL_COLUMN].astype(int)\r\n",
        "    data_x, data_y = convert_data(data_df)\r\n",
        "    return data_x, data_y"
      ],
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lg61oVflcsjY",
        "outputId": "eb145afe-3649-41aa-91ac-2f0c2225aef3"
      },
      "source": [
        "# 긍부정 문장을 포함하고 있는 칼럼\r\n",
        "DATA_COLUMN = \"Sentence\"\r\n",
        "# 긍정인지 부정인지를 (1=긍정,0=부정) 포함하고 있는 칼럼\r\n",
        "LABEL_COLUMN = \"label\"\r\n",
        "\r\n",
        "# train 데이터를 버트 인풋에 맞게 변환\r\n",
        "train_x, train_y = load_data(train)\r\n",
        "\r\n",
        "# validation 데이터를 버트 인풋에 맞게 변환\r\n",
        "validation_x, validation_y = load_data(val)\r\n",
        "\r\n",
        "# test 데이터를 버트 인풋에 맞게 변환\r\n",
        "test_x, test_y = load_data(test)"
      ],
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "  0%|          | 0/127500 [00:00<?, ?it/s]/usr/local/lib/python3.6/dist-packages/transformers/tokenization_utils_base.py:2179: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n",
            "100%|██████████| 127500/127500 [00:24<00:00, 5305.35it/s]\n",
            "100%|██████████| 22500/22500 [00:04<00:00, 5516.36it/s]\n",
            "100%|██████████| 50000/50000 [00:09<00:00, 5388.73it/s]\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "s1OtC62JaI8S"
      },
      "source": [
        "#### model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "a_YlM23laHHi",
        "outputId": "e27744d4-70b3-439c-b8d6-8eaaedfc9096"
      },
      "source": [
        "model = TFBertModel.from_pretrained(\"monologg/kobert\", from_pt=True)\r\n",
        "# 토큰 인풋, 마스크 인풋, 세그먼트 인풋 정의\r\n",
        "token_inputs = tf.keras.layers.Input((SEQ_LEN,), dtype=tf.int32, name='input_word_ids')\r\n",
        "mask_inputs = tf.keras.layers.Input((SEQ_LEN,), dtype=tf.int32, name='input_masks')\r\n",
        "segment_inputs = tf.keras.layers.Input((SEQ_LEN,), dtype=tf.int32, name='input_segment')\r\n",
        "# 인풋이 [토큰, 마스크, 세그먼트]인 모델 정의\r\n",
        "bert_outputs = model([token_inputs, mask_inputs, segment_inputs])"
      ],
      "execution_count": 46,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "All PyTorch model weights were used when initializing TFBertModel.\n",
            "\n",
            "All the weights of TFBertModel were initialized from the PyTorch model.\n",
            "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFBertModel for predictions without further training.\n",
            "The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n",
            "The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "886IbYsoaMAx",
        "outputId": "83b18e7a-6358-4aff-84ea-420d27d243e7"
      },
      "source": [
        "bert_outputs"
      ],
      "execution_count": 47,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "TFBaseModelOutputWithPooling([('last_hidden_state',\n",
              "                               <KerasTensor: shape=(None, 128, 768) dtype=float32 (created by layer 'tf_bert_model_1')>),\n",
              "                              ('pooler_output',\n",
              "                               <KerasTensor: shape=(None, 768) dtype=float32 (created by layer 'tf_bert_model_1')>)])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 47
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TM85m8neaNzZ"
      },
      "source": [
        "bert_outputs = bert_outputs[1]"
      ],
      "execution_count": 48,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HAnLF__laPoc"
      },
      "source": [
        "# Rectified Adam 옵티마이저 사용\r\n",
        "import tensorflow_addons as tfa\r\n",
        "opt = tfa.optimizers.RectifiedAdam(lr=5.0e-5, total_steps = ITERATIONS*EPOCHS, warmup_proportion=0.15, min_lr=1e-5, epsilon=1e-08, clipnorm=1.0)"
      ],
      "execution_count": 49,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7IUrq_cwaPsi"
      },
      "source": [
        "sentiment_drop = tf.keras.layers.Dropout(0.5)(bert_outputs)\r\n",
        "sentiment_first = tf.keras.layers.Dense(1, activation='sigmoid', kernel_initializer=tf.keras.initializers.TruncatedNormal(stddev=0.02))(sentiment_drop)\r\n",
        "sentiment_model = tf.keras.Model([token_inputs, mask_inputs, segment_inputs], sentiment_first)\r\n",
        "sentiment_model.compile(optimizer=opt, loss=tf.keras.losses.BinaryCrossentropy(), metrics = ['accuracy'])"
      ],
      "execution_count": 50,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kpZg7TCQaPvl",
        "outputId": "ffe9d5d8-aa18-40b7-ee1c-9bd3409c179a"
      },
      "source": [
        "sentiment_model.summary()"
      ],
      "execution_count": 51,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"model\"\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "input_word_ids (InputLayer)     [(None, 128)]        0                                            \n",
            "__________________________________________________________________________________________________\n",
            "input_masks (InputLayer)        [(None, 128)]        0                                            \n",
            "__________________________________________________________________________________________________\n",
            "input_segment (InputLayer)      [(None, 128)]        0                                            \n",
            "__________________________________________________________________________________________________\n",
            "tf_bert_model_1 (TFBertModel)   TFBaseModelOutputWit 92186880    input_word_ids[0][0]             \n",
            "                                                                 input_masks[0][0]                \n",
            "                                                                 input_segment[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "dropout_74 (Dropout)            (None, 768)          0           tf_bert_model_1[0][1]            \n",
            "__________________________________________________________________________________________________\n",
            "dense (Dense)                   (None, 1)            769         dropout_74[0][0]                 \n",
            "==================================================================================================\n",
            "Total params: 92,187,649\n",
            "Trainable params: 92,187,649\n",
            "Non-trainable params: 0\n",
            "__________________________________________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "j9cRSfT1ad6f"
      },
      "source": [
        "#### train"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "p9zBTNnKaPyP",
        "outputId": "b6e001aa-e317-4043-bcfe-e24e6b6e4a4f"
      },
      "source": [
        "sentiment_model.fit(train_x, train_y, epochs=EPOCHS, shuffle=True, batch_size=BATCH_SIZE, validation_data=(validation_x, validation_y))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n",
            "The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/5\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n",
            "The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            " 596/3985 [===>..........................] - ETA: 17:58 - loss: 0.7022 - accuracy: 0.4996"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xrIeRT2iaoFI"
      },
      "source": [
        "#### prediect"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IWPLkV-iajEk"
      },
      "source": [
        "def predict_convert_data(data_df):\r\n",
        "    global tokenizer\r\n",
        "    tokens, masks, segments = [], [], []\r\n",
        "    \r\n",
        "    for i in tqdm(range(len(data_df))):\r\n",
        "\r\n",
        "        token = tokenizer.encode(data_df[DATA_COLUMN][i], max_length=SEQ_LEN, pad_to_max_length=True)\r\n",
        "        num_zeros = token.count(0)\r\n",
        "        mask = [1]*(SEQ_LEN-num_zeros) + [0]*num_zeros\r\n",
        "        segment = [0]*SEQ_LEN\r\n",
        "\r\n",
        "        tokens.append(token)\r\n",
        "        segments.append(segment)\r\n",
        "        masks.append(mask)\r\n",
        "\r\n",
        "    tokens = np.array(tokens)\r\n",
        "    masks = np.array(masks)\r\n",
        "    segments = np.array(segments)\r\n",
        "    return [tokens, masks, segments]\r\n",
        "\r\n",
        "def predict_load_data(pandas_dataframe):\r\n",
        "    data_df = pandas_dataframe\r\n",
        "    data_df[DATA_COLUMN] = data_df[DATA_COLUMN].astype(str)\r\n",
        "    data_x = predict_convert_data(data_df)\r\n",
        "    return data_x"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qZi11MHVauiq"
      },
      "source": [
        "#### test"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "c_OVrtSiaqc8"
      },
      "source": [
        "test_set = predict_load_data(test)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3kL8mWqrasWk"
      },
      "source": [
        "test_set"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GqmV0yZbawwF"
      },
      "source": [
        "preds = sentiment_model.predict(test_set)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7qRViwtMa1D2"
      },
      "source": [
        "from sklearn.metrics import classification_report\r\n",
        "y_true = test['label']\r\n",
        "# F1 Score 확인\r\n",
        "print(classification_report(y_true, np.round(preds,0)))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "b7Rq7I5na4Iy"
      },
      "source": [
        "import logging\r\n",
        "tf.get_logger().setLevel(logging.ERROR)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RaCfkio1a5Fm"
      },
      "source": [
        "#### competition data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3jyt01kPa7i-"
      },
      "source": [
        "cptt_test = pd.read_csv(DATA_PATH + \"ko_data.csv\", sep=',', encoding='CP949')\r\n",
        "print(cptt_test.shape)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "p4Hg4zXTbADI"
      },
      "source": [
        "cptt_test[:5]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aA1SsQAdew9T"
      },
      "source": [
        "cptt_set = predict_load_data(cptt_test)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iCm1hNCwe7sH"
      },
      "source": [
        "cptt_predict_label = sentiment_model.predict(cptt_set)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OIv4lyvBfFHf"
      },
      "source": [
        "print(cptt_predict_label)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Onhuf1Cn8Eua"
      },
      "source": [
        "df0 = pd.DataFrame(data=cptt_test['Id'], columns=['Id'])\r\n",
        "df1 = pd.DataFrame(data=np.round(cptt_predict_label,0),columns=['Predicted'])\r\n",
        "\r\n",
        "final_predicted = pd.concat([df0, df1], axis=1)\r\n",
        "final_predicted[:5]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "t20sRu7saN4g"
      },
      "source": [
        "final_predicted.to_csv(DATA_PATH + 'sample.csv', index=False)"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}